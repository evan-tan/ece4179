{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Residual and Skip Connections</h1>\n",
    "As we've seen up until now neural networks can learn a lot of interesting things! But much of the data has been of a very simple nature. In this lab we are going to try and train with data that is a bit more complicated, the CIFAR10 dataset. CIFAR10 images are much more complicated then MNIST images and even though they are only 3x32x32 they have about 4x as much data as MNIST! Now image using high resolution images!<br>\n",
    "So let's just bigger neural networks right? In general there are two ways we can increase the size of the neural networks we have seen up until now, by increasing the width (parameters per layer) and the depth (number of layers).<br>\n",
    "So which is better?<br>\n",
    "Well..... it's complicated<br>\n",
    "Via empirical studies it is easy to show that by increasing the model's width the network's performance on a validation set does increase, up until a point then the model with a huge number of parameters starts to overfit on the training set and performance on the validation set DECREASES never reaching even close to 100%. Instead it has been shown that increasing the DEPTH of our model is far more effective. The verdict is STILL out on why this is but theories include:<br>\n",
    "-Every layer performs independent \"operations\" (like steps in a program) more steps are better<br>\n",
    "-Information is \"distilled\" layer to layer so each layer receives a refined version of the input and so cannot overfit<br>\n",
    "-Adding a new layer creates more paths for the data to flow to the output then does adding more width\n",
    "\n",
    "So we'll just add more layers!! Well... it's not that simple\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1000/1*aqmUx_ONo8KqKNEYsjM8eA.png)\n",
    "\n",
    "[Why ResNets?](https://mc.ai/what-are-deep-residual-networks-or-why-resnets-are-important/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the size of our mini batches\n",
    "batch_size     = 64\n",
    "#How many itterations of our dataset\n",
    "num_epochs     = 10\n",
    "#optimizer learning rate\n",
    "learning_rate  = 1e-4\n",
    "#initialise what epoch we start from\n",
    "start_epoch    = 0\n",
    "#initialise best valid accuracy \n",
    "best_valid_acc = 0\n",
    "#where to load/save the dataset from \n",
    "data_set_root = \"data\"\n",
    "\n",
    "start_from_checkpoint = False\n",
    "save_dir = 'Models'\n",
    "model_name = 'Res_net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set device to GPU_indx if GPU is avaliable\n",
    "GPU_indx = 0\n",
    "device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create a transform for the input data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare a composition of transforms\n",
    "#transforms.Compose will perform the transforms in order\n",
    "#NOTE some transform only take in a PIL image, others only a Tensor\n",
    "#EG Resize and ToTensor take in a PIL Image, Normalize takes in a Tensor\n",
    "#Refer to documentation\n",
    "#https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create the training, testing and validation data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use the CIFAR10 dataset!\n",
    "train_data = datasets.CIFAR10(data_set_root, train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(data_set_root, train=False, download=True, transform=transform)\n",
    "\n",
    "#We are going to split the test dataset into a test and validation set 50/50\n",
    "validation_split = 0.5\n",
    "\n",
    "#Determine the number of samples for each split\n",
    "n_train_examples = int(len(test_data)*validation_split)\n",
    "n_valid_examples = len(test_data) - n_train_examples\n",
    "\n",
    "#The function random_split will take our dataset and split it randomly and give us dataset\n",
    "#that are the sizes we gave it\n",
    "#Note: we can split it into to more then two pieces!\n",
    "test_data, valid_data = torch.utils.data.random_split(test_data, [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create the dataloader</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training, Validation and Evaluation/Test Datasets\n",
    "#It is best practice to separate your data into these three Datasets\n",
    "#Though depending on your task you may only need Training + Evaluation/Test or maybe only a Training set\n",
    "#(It also depends on how much data you have)\n",
    "#https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "train_loader = dataloader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = dataloader(valid_data, batch_size=batch_size)\n",
    "test_loader  = dataloader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Check the lengths of all the datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lets visualize some data!</h3>\n",
    "CIFAR10 is a dataset of 32*32 colour images with 10 classes of animals and vehicles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataloader itterable object\n",
    "dataiter = iter(train_loader)\n",
    "#sample from the itterable object\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets visualise an entire batch of images!\n",
    "plt.figure(figsize = (20,10))\n",
    "out = torchvision.utils.make_grid(images, 8)\n",
    "plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating Deep Networks</h2>\n",
    "So we'll just make our Networks deeper!<br>\n",
    "Well, it's not that simple, not only does adding more layers mean our model is more sequential (rather than parallel, meaning forward and backward passes are slower) but we now face the problem of \"Vanishing Gradients\".<br>\n",
    "When we create larger and larger networks, something funny happens when we try and train them, the gradients that are back propagated from the output become tiny (near zero) for layers near the top. They seem to \"vanish\"! But why!? Well in most models gradients become smaller as they backpropagate through a network. This is easiest to understand by looking at our networks parameters and thinking about how gradients are back propagated. In general gradients are back propagated by multiplying together the weights of layers sequentially. As the weights of our models are tiny (much less then zero in magnitude) multiplying many of them together gives us a VERY small result. This problem becomes worse the deeper it is! As a result the top layers of our network barely move from their random initialisations and in effect aren't trained!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Enter the Skip and Residual Connection!</h3>\n",
    "Skip and Residual connection allow us to have our deep networks and train them too!<br>\n",
    "So what are they?<br>\n",
    "In simple terms we take the output of some layer and \"skip\" some number of layers and combine it with the hidden layer of a much later layer. One result of this is that, during backpropagation, the gradients have a shorter minimum path to the input layers, reducing the impact of the vanishing gradient!<br>\n",
    "There are a couple of ways to combine hidden layers together, by adding them together or concatenating the tensors.<br>\n",
    "Adding the hidden layers together (often called a Residual Connection) means that the size of the layers must be the same which for the networks we've seen until now has not been the case (size usually decreases). However with residual connections we don't necessarily need to add the hidden layers directly. For example, we can take a hidden layer and skip two layers, by passing it through a single layer (that will transform it to the right size) halving the length of the path for gradients.<br>\n",
    "Concatenating hidden layers involves simply \"sticking together\" the tensors. This not only helps with the vanishing gradient problem but also helps information from the input penetrate deeper into the network.\n",
    "\n",
    "\n",
    "![alt text](https://miro.medium.com/max/1140/1*D0F3UitQ2l5Q0Ak-tjEdJg.png)\n",
    "A simple \"Identity\" resdual connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modules in Modules</h3>\n",
    "To simplify the creation os our residual and skip networks we will create seperate nn.modules of the skip and residual \"blocks\" and then create our \"top level\" network with these!<br>\n",
    "NOTE: For simplicity all these blocks return an output the same size as their input though this does not have to be the case!\n",
    "NOTE: We also introduce \"Batch Normalisation\" layers here for more info:\n",
    "\n",
    "[Batch Normalisation](https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First block demonstraights a simple identity residual connection\n",
    "\n",
    "############TO DO#############\n",
    "##############################\n",
    "class Res_block(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        #Call the __init__ function of the parent nn.module class\n",
    "        super(Res_block, self).__init__()\n",
    "        \n",
    "        self.conv1 = ##Conv2d channels, channels//2, kernel 3x3, stride 1, padding 1\n",
    "        #Batch normalisation layer channels in = channels out\n",
    "        self.bn1 = nn.BatchNorm2d(channels//2)\n",
    "        self.conv2 = ##Conv2d channels//2, channels, kernel 3x3, stride 1, padding 1\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##store the input\n",
    "        x0 = x\n",
    "        x = ##Perform conv1. batchnorm1, relu##\n",
    "        x = ##Perform conv2. batchnorm2##\n",
    "        x = ##add input to ouput of batchnorm2\n",
    "        x = ##relu output##\n",
    "        \n",
    "        return x\n",
    "#################################\n",
    "#################################\n",
    "\n",
    "#Second block demonstraights how we can use a \"side layer\" in our residual block to \n",
    "#Change the shape of the tensors so they match later layers\n",
    "#The channels change in this case but you could also create one where the feature map size changes\n",
    "class ResDown_block(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        #Call the __init__ function of the parent nn.module class\n",
    "        super(ResDown_block, self).__init__()\n",
    "        #how to handle channel width change\n",
    "        self.conv1 = nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(channels_out, channels_out, kernel_size=3, stride=1, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels_out)\n",
    "        \n",
    "        self.convRes = nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=1, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.convRes(x)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "         \n",
    "        x = F.relu(x + x0)\n",
    "        return x\n",
    "\n",
    "#Third block is a simple skip connection\n",
    "#The layers downsamples to half the input size channel size\n",
    "#and then concatenates the first hidden layer (x1) to the last output (x1) along the channels\n",
    "#creating a tensor that is the same shape as the input\n",
    "class Skip_block(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        #Call the __init__ function of the parent nn.module class\n",
    "        super(Skip_block, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, channels//2,  kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels//2)\n",
    "        self.conv2 = nn.Conv2d(channels//2, channels//2,  kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels//2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1= F.relu(self.BN1(self.conv1(x)))\n",
    "        x2= F.relu(self.bn2(self.conv2(x1)))\n",
    "        return torch.cat((x1,x2),1)\n",
    "\n",
    "#We will use the above blocks to create a \"Deep\" neural network with many layers!\n",
    "class Deep_CNN(nn.Module):\n",
    "    def __init__(self, channels_in, num_blocks = 2, layer_type = Res_block):\n",
    "        #Call the __init__ function of the parent nn.module class\n",
    "        super(Deep_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels_in, 16, kernel_size=4, stride=2)\n",
    "        #Batch normalisation is very common in deep learning \n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.layers = self.create_blocks(num_blocks, layer_type, channels = 64)\n",
    "\n",
    "        self.linear1 = nn.Linear(64*3*3, 10)\n",
    "\n",
    "        #This function will create a nn.Sequential block from a list of Pytorch layers\n",
    "        #A forward pass though the Sequential block will perform a forward pass\n",
    "        #though the layers in the order they appear in the list\n",
    "    def create_blocks(self, num_blocks, block_type, channels = 64):\n",
    "        blocks = []\n",
    "        \n",
    "        #We will add some number of the res/skip blocks!\n",
    "        for _ in range(num_blocks):\n",
    "            blocks.append(block_type(channels))\n",
    "\n",
    "        return nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Pass input through conv layers\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        #Pass through the block of res/skip blocks!\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        #Flatten it for the final linear layer!\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        #Ouput the class acitvations!\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating our Network</h3>\n",
    "When creating an instance of our network we will also specify the type of block we will use!<br>\n",
    "The next bit of code should be familiar to you, try experimenting with the different layer types and see the different results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of our network\n",
    "#set channels_in to the number of channels of the dataset images\n",
    "net = ##TO DO##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have a look at our network structure!\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass image through network\n",
    "out = net(images.to(device))\n",
    "#check output\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass our network parameters to the optimiser set our lr as the learning_rate\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "#Define a Cross Entropy Loss\n",
    "Loss_fun = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Save Path from save_dir and model_name, we will save and load our checkpoint here\n",
    "Save_Path = os.path.join(save_dir, model_name + \".pt\")\n",
    "\n",
    "#Create the save directory if it does note exist\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "#Load Checkpoint\n",
    "if start_from_checkpoint:\n",
    "    #Check if checkpoint exists\n",
    "    if os.path.isfile(Save_Path):\n",
    "        #load Checkpoint\n",
    "        check_point = torch.load(Save_Path)\n",
    "        #Checkpoint is saved as a python dictionary\n",
    "        #https://www.w3schools.com/python/python_dictionaries.asp\n",
    "        #here we unpack the dictionary to get our previous training states\n",
    "        net.load_state_dict(check_point['model_state_dict'])\n",
    "        optimizer.load_state_dict(check_point['optimizer_state_dict'])\n",
    "        start_epoch = check_point['epoch']\n",
    "        best_valid_acc = check_point['valid_acc']\n",
    "        print(\"Checkpoint loaded, starting from epoch:\", start_epoch)\n",
    "    else:\n",
    "        #Raise Error if it does not exist\n",
    "        raise ValueError(\"Checkpoint Does not exist\")\n",
    "else:\n",
    "    #If checkpoint does exist and Start_From_Checkpoint = False\n",
    "    #Raise an error to prevent accidental overwriting\n",
    "    if os.path.isfile(Save_Path):\n",
    "        raise ValueError(\"Warning Checkpoint exists\")\n",
    "    else:\n",
    "        print(\"Starting from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(fx, y):\n",
    "    preds = fx.max(1, keepdim=True)[1]\n",
    "    correct = preds.eq(y.view_as(preds)).sum()\n",
    "    acc = correct.float()/preds.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function should perform a single training epoch using our training data\n",
    "def train(net, device, loader, optimizer, Loss_fun, loss_logger):\n",
    "    \n",
    "    #initialise counters\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #Set Network in train mode\n",
    "    net.train()\n",
    "    \n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        \n",
    "        #load images and labels to device\n",
    "        x = x.to(device) # x is the image\n",
    "        y = y.to(device) # y is the corresponding label\n",
    "                \n",
    "        #Forward pass of image through network and get output\n",
    "        fx = net(x)\n",
    "        \n",
    "        #Calculate loss using loss function\n",
    "        loss = Loss_fun(fx, y)\n",
    "        \n",
    "        #calculate the accuracy\n",
    "        acc = calculate_accuracy(fx, y)\n",
    "\n",
    "        #Zero Gradents\n",
    "        optimizer.zero_grad()\n",
    "        #Backpropagate Gradents\n",
    "        loss.backward()\n",
    "        #Do a single optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        #create the cumulative sum of the loss and acc\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        #log the loss for plotting\n",
    "        loss_logger.append(loss.item())\n",
    "\n",
    "        #clear_output is a handy function from the IPython.display module\n",
    "        #it simply clears the output of the running cell\n",
    "        \n",
    "        clear_output(True)\n",
    "        print(\"TRAINING: | Itteration [%d/%d] | Loss %.2f |\" %(i+1 ,len(loader) , loss.item()))\n",
    "        \n",
    "    #return the avaerage loss and acc from the epoch as well as the logger array       \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader), loss_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function should perform a single evaluation epoch and will be passed our validation or evaluation/test data\n",
    "#it WILL NOT be used to train out model\n",
    "def evaluate(net, device, loader, Loss_fun, loss_logger = None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #Set network in evaluation mode\n",
    "    #Layers like Dropout will be disabled\n",
    "    #Layers like Batchnorm will stop calculating running mean and standard deviation\n",
    "    #and use current stored values\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            \n",
    "            #load images and labels to device\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #Forward pass of image through network\n",
    "            fx = net(x)\n",
    "            \n",
    "            #Calculate loss using loss function\n",
    "            loss = Loss_fun(fx, y)\n",
    "            \n",
    "            #calculate the accuracy\n",
    "            acc = calculate_accuracy(fx, y)\n",
    "            \n",
    "            #log the cumulative sum of the loss and acc\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "            #log the loss for plotting if we passed a logger to the function\n",
    "            if not (loss_logger is None):\n",
    "                loss_logger.append(loss.item())\n",
    "            \n",
    "            clear_output(True)\n",
    "            print(\"EVALUATION: | Itteration [%d/%d] | Loss %.2f | Accuracy %.2f%% |\" %(i+1 ,len(loader), loss.item(), 100*(epoch_acc/ len(loader))))\n",
    "    \n",
    "    #return the avaerage loss and acc from the epoch as well as the logger array       \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader), loss_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell implements our training loop\n",
    "training_loss_logger = []\n",
    "validation_loss_logger = []\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    \n",
    "    #call the training function and pass training dataloader etc\n",
    "    train_loss, train_acc, training_loss_logger = train(net, device, train_loader, optimizer, Loss_fun, training_loss_logger)\n",
    "    \n",
    "    #call the evaluate function and pass validation dataloader etc\n",
    "    valid_loss, valid_acc, validation_loss_logger = evaluate(net, device, valid_loader, Loss_fun, validation_loss_logger)\n",
    "\n",
    "    #If this model has the highest performace on the validation set \n",
    "    #then save a checkpoint\n",
    "    #{} define a dictionary, each entry of the dictionary is indexed with a string\n",
    "    if (valid_acc > best_valid_acc):\n",
    "        print(\"Saving Model\")\n",
    "        torch.save({\n",
    "            'epoch':                 epoch,\n",
    "            'model_state_dict':      net.state_dict(),\n",
    "            'optimizer_state_dict':  optimizer.state_dict(), \n",
    "            'train_acc':             train_acc,\n",
    "            'valid_acc':             valid_acc,\n",
    "        }, Save_Path)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:05.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "train_x = np.linspace(0, num_epochs, len(training_loss_logger))\n",
    "plt.plot(train_x, training_loss_logger, c = \"y\")\n",
    "valid_x = np.linspace(0, num_epochs, len(validation_loss_logger))\n",
    "plt.plot(valid_x, validation_loss_logger, c = \"k\")\n",
    "\n",
    "plt.title(\"LeNet\")\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the evaluate function and pass the evaluation/test dataloader etc\n",
    "test_loss, test_acc, _ = evaluate(net, device, test_loader, Loss_fun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
