{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9545dd",
   "metadata": {},
   "source": [
    "# Interpretable Explanations \n",
    "\n",
    "___\n",
    "\n",
    "Let’s start with a motivating example. Consider a classifier that is able to recognize whether there is a wolf or a husky dog in the photo (see the image below). The classfier has a high precision – it is only wrong once. The model incorrectly classified the image in the lower left corner as a wolf, although in reality it is a husky dog. The remaining images were classified correctly.\n",
    "<img src=\"images/husky_wolf1.png\" alt=\"husky_wolf\" style=\"float: left; margin-right: 10px;\"  width=\"600\"/>\n",
    "Now the question is: __Can we reliably employ this model?__ \n",
    "\n",
    "\n",
    "Now check  the illustration below in which, we used an interpretablity technique to see which parts of the picture were informative for the classifier. The gray parts are less relevant to the decision of the classifier in each image. It turns out that our classifier, instead of identifying wolves, detects **snow**! \n",
    "<img src=\"images/husky_wolf2.png\" alt=\"husky_wolf2\" style=\"float: left; margin-right: 10px;\"  width=\"600\"/>\n",
    "\n",
    "If not for the approach to explainability of artificial intelligence models, we would not know that decisions were made on the basis of the wrong parts of the photo.\n",
    "**Do not** trust the model blindly! We need to understand how our models work and try to generate explanations.\n",
    "In this notebook, we will learn about [**Local Interpretable Model-agnostic Explanations**](https://arxiv.org/abs/1602.04938) or LIME for short. \n",
    "<img src=\"images/lime_logo.jpg\" alt=\"lime_logo\" style=\"float: left; margin-right: 10px;\" align=\"center\" width=\"100\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a286a7",
   "metadata": {},
   "source": [
    "## How does LIME work?\n",
    "\n",
    "The easiest solution to the interpretability problem is to use the so called “interpretable” models, such as a linear model or a decision tree. Consider as an example, a perceptron. The weight associated to each feature of the input is a proxy of how important that feature is. Here, of course, we assume all features are normalized in the same range (say $[0,1]$). Now, if for say feature 5, the weight of the perceptron is 1000 while the weight of feature 32 is -0.2, you can comfortably say that feature 5 is more important for decisions than frature 32. Just recall that\n",
    "\\begin{align}\n",
    "f(\\mathbf{x}) = \\mathrm{sign}\\big(w_1x[1] + w_2x[2] + \\cdots + w_nx[n]\\big) \n",
    "\\end{align}\n",
    "\n",
    "As long as the model is accurate for the task, and uses a reasonably restricted number of parameters, such approaches provide extremely useful insights. But what about more involved and non-linear models such as Deep Neural Networks (DNNs)?\n",
    "\n",
    "### Interpretability for black-box models\n",
    "\n",
    "The black-box model’s complex decision function $f$ (unknown to LIME) is represented by the blue/pink background, which cannot be approximated well by a linear model. The bold red cross is the instance being explained. LIME samples instances, gets predictions using $f$, and weighs them by the proximity to the instance being explained (represented here by size). The dashed line is the learned explanation that is locally (but not globally) faithful.\n",
    "\n",
    "<img src=\"images/lime.png\" alt=\"lime_expl\" style=\"float: left; margin-right: 10px;\"  width=\"600\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf16162",
   "metadata": {},
   "source": [
    "## LIME package for Python\n",
    "\n",
    "In this notebook, we will use the [LIME package](https://github.com/marcotcr/lime) for python. You can simply install the package on your machine by invoking\n",
    "\n",
    "<pre>\n",
    "pip install lime\n",
    "</pre>\n",
    "\n",
    "\n",
    "\n",
    "As mentioned above, LIME takes a model $f$ and an individual sample $x$ and generates data by perturbing $x$ (switching on/off the features of $x$). It then calculates a similarity metric between perturbed data and $x$. This helps to understand how similar perturbed  data is compared to the original sample $x$. The lime library methods provide us with options to try different similarity metrics for this purpose.\n",
    "\n",
    "The LIME algorithm then makes predictions on the perturbed data using the black-box model $f$.\n",
    "It then picks features that best describe the black-box model $f$ model's performance on perturbed data. \n",
    "The library let us provide how many features to pick up.\n",
    "\n",
    "The library then fits a simple model (like linear or logistic regression) on the combination of perturbed data taking into account the similarity scores computed in the earlier step. The lime library lets us provide a simple model that we want to use. Generally, it is linear regression or logistic regression but we can change it.\n",
    "\n",
    "It then uses weights derived from that simple model for each feature to explain how each feature contributed to making a prediction for that sample when predicted using an original complex model.\n",
    "The lime package has three main modules which can be used with different types of datasets:\n",
    "\n",
    "1. **lime_tabular** - used for generating explanations for structured datasets.\n",
    "2. **lime_text** - used for generating explanations for text datasets.\n",
    "3. **lime_image** - used for generating explanations for image datasets.\n",
    "\n",
    "We are working with the lime_tabular and lime_image in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21088e4",
   "metadata": {},
   "source": [
    "## LIME for tabular data\n",
    "\n",
    "\n",
    "<img src=\"images/Breast-Cancer-Ribbon.png\" alt=\"ribbon_logo\" style=\"float: left; margin-right: 10px;\" align=\"right\" width=\"200\"/>\n",
    "We will use LIME for a binary classification problem using the Wisconsin breast cancer dataset available from <a href=\"https://archive-beta.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+diagnostic\">UCI machine learning repository</a>. The dataset contains features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. See below for a brief  description of each sample in the dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**1.** ID number <br>\n",
    "**2.** Diagnosis (M = malignant, B = benign) <br>\n",
    "**3 - 32** Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "1. radius (mean of distances from center to points on the perimeter)\n",
    "2. texture (standard deviation of gray-scale values)\n",
    "3. perimeter\n",
    "4. area\n",
    "5. smoothness (local variation in radius lengths)\n",
    "6. compactness (perimeter^2 / area - 1.0)\n",
    "7. concavity (severity of concave portions of the contour)\n",
    "8. concave points (number of concave portions of the contour)\n",
    "9. symmetry\n",
    "10. fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torch and related packages\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# reading lime_tabular\n",
    "from lime import lime_tabular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aadb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility.\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0) \n",
    "\n",
    "\n",
    "device =\"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb25116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "wdbc_pd = pd.read_csv(os.path.join(\"data\",\"breast-cancer.csv\"))\n",
    "\n",
    "# let's check the records\n",
    "wdbc_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bae58",
   "metadata": {},
   "source": [
    "### Cleaning data\n",
    "\n",
    "There are some rubbish features that we need to remove from our data. \n",
    "1. Check the data above, identify them and remove them using Pandas function [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html).\n",
    "\n",
    "2. the diagnosis column is categorical data, we need to convert that to 0 for benign and 1 for malignent cases. Pandas basic functionalities are exaplained [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the id column\n",
    "wdbc_pd = wdbc_pd.drop([\"id\",\"Unnamed: 32\"], axis=1)\n",
    "\n",
    "# replace M with 1 and B with 0 for the diagnosis column\n",
    "diag_map = {'M':1, 'B':0}\n",
    "wdbc_pd[\"diagnosis\"] = wdbc_pd[\"diagnosis\"].map(diag_map)\n",
    "\n",
    "# print the records\n",
    "wdbc_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a477b1d",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "Since LIME works with numpy arrays, we convert Pandas DataFrame to a numpy array below. We also create training and test data below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and labels to numpy arrays.\n",
    "wdbc_labels = wdbc_pd[\"diagnosis\"].to_numpy()\n",
    "wdbc_pd = wdbc_pd.drop([\"diagnosis\"], axis=1)\n",
    "feature_names = list(wdbc_pd.columns)\n",
    "wdbc_data = wdbc_pd.to_numpy()\n",
    "\n",
    "# normalizing features so the features are normalized to the range [0,1]\n",
    "wdbc_data -= np.min(wdbc_data, axis=0) # removing the mean\n",
    "wdbc_data /= np.max(wdbc_data, axis=0) # divide by the max \n",
    "\n",
    "\n",
    "# create training and test sets \n",
    "# randomly choose 90% of data as training set\n",
    "trn_idx = np.random.choice(len(wdbc_labels), int(0.9*len(wdbc_labels)), replace=False) \n",
    "trn_data = wdbc_data[trn_idx]        # training data\n",
    "trn_labels = wdbc_labels[trn_idx]    # training labels\n",
    "# choose the remaining 10% as test data\n",
    "tst_idx = list(set(range(len(wdbc_labels))) - set(trn_idx))\n",
    "tst_data = wdbc_data[tst_idx]\n",
    "tst_labels = wdbc_labels[tst_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254283a",
   "metadata": {},
   "source": [
    "## MLP to classify breast cancer data\n",
    "\n",
    "We will use an MLP with 1 hidden layer to classify our data. Implement an MLP and be courages with activation function (eg., use LeakyReLU).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad338f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WDBC_MLP(nn.Module):\n",
    "    def __init__(self, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.fc1  = nn.Linear(30, hidden_size)\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.fc2  = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        fc1_out = self.relu(self.fc1(x))\n",
    "        fc2_out = self.fc2(fc1_out)\n",
    "        return fc2_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be91e5",
   "metadata": {},
   "source": [
    "### Utility functions\n",
    "\n",
    "1. write a function to accept a numpy array and predict the response of your MLP per each row of that array. Again, recall that LIME works with numpy array so you need to convert its data to torch.\n",
    "\n",
    "2. write a function to evaluate your network on training and testing data. We will use this for training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3696621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_WDBC_MLP(inp_array_numpy):\n",
    "    net.eval()\n",
    "    inp_tensor = torch.from_numpy(inp_array_numpy).type(torch.FloatTensor).to(device)    \n",
    "    logits = net(inp_tensor)\n",
    "    probs = F.softmax(logits, dim=1).detach().numpy()\n",
    "    return probs  \n",
    "\n",
    "\n",
    "def evaluate_WDBC_MLP(trn_data,trn_labels,tst_data,tst_labels):\n",
    "    out_probs = predict_WDBC_MLP(trn_data)\n",
    "    out_classes_trn = np.argmax(out_probs, axis=1)\n",
    "    out_probs = predict_WDBC_MLP(tst_data)\n",
    "    out_classes_tst = np.argmax(out_probs, axis=1)\n",
    "    trn_acc = sum(out_classes_trn == trn_labels) / len(trn_labels)\n",
    "    tst_acc = sum(out_classes_tst == tst_labels) / len(tst_labels)\n",
    "    return trn_acc, tst_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7f187",
   "metadata": {},
   "source": [
    "### Train MLP \n",
    "\n",
    "- Train your MLP for a few epochs below\n",
    "- Use Adam as optimizer for efficiency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = WDBC_MLP(hidden_size=64).to(device)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 50\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "input_tensor = torch.from_numpy(trn_data).type(torch.FloatTensor).to(device)\n",
    "label_tensor = torch.from_numpy(trn_labels).to(device)\n",
    "for epoch in range(num_epochs):   \n",
    "    net.train()\n",
    "    output = net(input_tensor)\n",
    "    loss = criterion(output, label_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    trn_acc, tst_acc = evaluate_WDBC_MLP(trn_data,trn_labels,tst_data,tst_labels)\n",
    "    if epoch % 10 == 0:\n",
    "        print ('Epoch {:>3}/{:>3}: Loss = {:.2f}, train accuracy = {:.2f}, test accuracy = {:.2f}'.format(epoch+1, \n",
    "                                                                                                    num_epochs,\n",
    "                                                                                                    loss.item(),\n",
    "                                                                                                    100*trn_acc,\n",
    "                                                                                                    100*tst_acc))\n",
    "\n",
    "torch.save(net, 'models/wdbc_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff92371",
   "metadata": {},
   "source": [
    "### Define the LIME explainer\n",
    "\n",
    "To use LIME for tabular data, we need to first define an explainer object and provide it with relervant information about our task and data. Check the cell below for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45134b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "WDBC_class_names = [\"benign\", \"malignant\"]\n",
    "explainer = lime_tabular.LimeTabularExplainer(trn_data, mode=\"classification\",\n",
    "                                              class_names=WDBC_class_names,\n",
    "                                              feature_names=feature_names,\n",
    "                                             )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c679047",
   "metadata": {},
   "source": [
    "### Use LIME to explain a sample\n",
    "\n",
    "Now, we can use the method [explain_instance](https://lime-ml.readthedocs.io/en/latest/lime.html#lime.lime_tabular.LimeTabularExplainer.explain_instance) from the explainer object to understand the behaviour of MLP. Run the \"explain_instance\" and analyze and discuss the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "inp_explainer = np.expand_dims(tst_data[idx], axis=0)\n",
    "explanation = explainer.explain_instance(tst_data[idx], predict_WDBC_MLP,\n",
    "                                         num_features=len(feature_names))\n",
    "\n",
    "print(\"Prediction : \", WDBC_class_names[np.argmax(predict_WDBC_MLP(inp_explainer))])\n",
    "print(\"Actual :     \", WDBC_class_names[tst_labels[idx]])\n",
    "\n",
    "explanation.show_in_notebook()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e4250a",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)\n",
    "\n",
    "2. [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)\n",
    "\n",
    "3. [How do machine learning algorithms work?\n",
    "On the example of LIME and model explainability](https://theblue.ai/blog/lime-models-explanation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9afe46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
