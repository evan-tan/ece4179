{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE4179 - Assignment 1\n",
    "Evan Tan 27401995 \\\n",
    "etan0008@student.monash.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMENT CELL BELOW WHEN SUBMITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray):\n",
    "    \"\"\"Computes the sigmoid of x\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    \"\"\"Predict labels based on learned model parameters\n",
    "    :param X: (M,N) samples, where M is the number of samples\n",
    "    :type X: np.ndarray\n",
    "    :param theta: (1,N) model parameters, N = number of features\n",
    "    :type theta: np.ndarray\n",
    "    :return: predictions of labels\n",
    "    :rtype: np.ndarray.astype(int)\n",
    "    \"\"\"\n",
    "    # jank boolean conversion\n",
    "    return (sigmoid(X @ theta.T) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_loss(X, y, theta):\n",
    "    \"\"\"Compute gradient and loss\"\"\"\n",
    "    # alternative\n",
    "    # epsilon = 7.0 / 3 - 4.0 / 3 - 1\n",
    "    sig_wx = sigmoid(X @ theta.T)\n",
    "    loss = -np.mean(\n",
    "        y * np.log(sig_wx + np.finfo(float).eps)\n",
    "        + (1 - y) * np.log(1 - sig_wx + np.finfo(float).eps)\n",
    "    )\n",
    "    # numpy still screams log(0) errors using this\n",
    "    # sig_wx[sig_wx < np.finfo(float).eps] = np.finfo(float).eps\n",
    "    # loss = -np.mean(y * np.log(sig_wx) + (1 - y) * np.log(1 - sig_wx))\n",
    "\n",
    "    # calculate mean across all datapoints\n",
    "    grad_vec = (sig_wx - y).T @ X / X.shape[0]\n",
    "    # alternatively\n",
    "    # grad_vec = np.mean((sig_wx - y) * X, axis=0, keepdims=True)\n",
    "\n",
    "    return loss, grad_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_gradient_descent(LR=5e-2, epochs=1e3):\n",
    "    \"\"\"Perform gradient descent\"\"\"\n",
    "    np.random.seed(0)\n",
    "    # randomly initilize theta, the parameters of the logistic model\n",
    "    # theta = np.random.randn(X_train.shape[1], 1)  # shape (2,1)\n",
    "    theta = np.random.randn(1, X_train.shape[1])  # shape (1,2)\n",
    "\n",
    "    # this is the learning rate of the GD algorithm, you need to tune this\n",
    "    # and study its effects in your report\n",
    "    lr = LR\n",
    "\n",
    "    # this is the maximum number of iterations of the GD algorithm.\n",
    "    # Since we use the GD, each iteration of the algorithm is equivalent\n",
    "    # to one epoch, hence the name\n",
    "    max_epoch = int(epochs)\n",
    "\n",
    "    # keep track of the loss/accuracy values for plotting\n",
    "    loss = np.zeros(max_epoch)\n",
    "    accuracy = np.zeros(max_epoch)\n",
    "    log_interval = max_epoch // 10\n",
    "    for epoch in range(max_epoch):\n",
    "        # call the compute_grad_loss that you have implemented above to\n",
    "        # measure the loss and the gradient\n",
    "        loss[epoch], grad_vec = compute_grad_loss(X_train, y_train, theta)\n",
    "        # update the theta parameter according to the GD here\n",
    "        theta -= lr * grad_vec\n",
    "\n",
    "        # storage for plotting\n",
    "        y_test_hat = predict(X_test, theta)\n",
    "        accuracy[epoch] = float(sum(y_test_hat == y_test)) / float(len(y_test))\n",
    "\n",
    "        if (epoch + 1) % log_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch:{epoch+1}/{max_epoch} \\\n",
    "                Loss: {loss[epoch]:.6f} \\\n",
    "                Acc: {accuracy[epoch]:.6f}\"\n",
    "            )\n",
    "    return theta, loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nonlinear(X):\n",
    "    \"\"\"Augment dataset from 2D to 5D feature space\"\"\"\n",
    "    X = np.c_[X, X[:, 0] ** 2, X[:, 1] ** 2, X[:, 0] * X[:, 1]]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(\"toy_data.npz\")  # toy_data.npz or toy_data_two_circles.npz\n",
    "# npzfile = np.load(\"toy_data_two_circles.npz\")\n",
    "\n",
    "# remember that each row in X_train and X_test is a sample. so X_train[0,:] is the first training sample\n",
    "X_train = npzfile[\"arr_0\"]\n",
    "X_test = npzfile[\"arr_1\"]\n",
    "y_train = npzfile[\"arr_2\"]\n",
    "y_test = npzfile[\"arr_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_bias = True\n",
    "augment_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"circles\" in npzfile.fid.name and augment_data:\n",
    "    X_train = make_nonlinear(X_train)\n",
    "    X_test = make_nonlinear(X_test)\n",
    "\n",
    "if add_bias:\n",
    "    X_train = np.c_[X_train, np.ones([X_train.shape[0], 1])]\n",
    "    X_test = np.c_[X_test, np.ones([X_test.shape[0], 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.scatter(\n",
    "    X_train[:, 0], X_train[:, 1], marker=\"o\", c=y_train[:, 0], s=25, edgecolor=\"k\"\n",
    ")\n",
    "plt.subplot(122)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], marker=\"o\", c=y_test[:, 0], s=25, edgecolor=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that you have trained your model, let's evaluate it\n",
    "# first call the predict function on your test data with\n",
    "# the parameters obtained by GD\n",
    "theta, loss, accuracy = do_gradient_descent(LR=0.5, epochs=1e3)\n",
    "y_test_hat = predict(X_test, theta)\n",
    "\n",
    "print()\n",
    "\n",
    "# make sure that the predictions are either 0 or 1 and the shape of y_test_hat\n",
    "print((y_test_hat >= 0).all() and (y_test_hat <= 1).all())\n",
    "print(y_test_hat.shape == y_test.shape)\n",
    "\n",
    "# the script below, if the dimensionality of the arrays is set correctly,\n",
    "# will measure how many samples are correctly classified by your model\n",
    "score = float(sum(y_test_hat == y_test)) / float(len(y_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loss and Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(accuracy, \"r-\")\n",
    "ax2.plot(loss, \"g-\")\n",
    "\n",
    "ax1.set_xlabel(\"Number of epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\", color=\"r\")\n",
    "ax2.set_ylabel(\"Loss\", color=\"g\")\n",
    "plt.title(\"Test Accuracy and Training Loss\")\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Learning Rate Tuning\n",
    "Instability: Begins at 15 in terms of accuracy curve, but 20 for loss curve \\\n",
    "Slow Convergence: 5e-5 and below (if too low it does not converge in 1000 epochs) \\\n",
    "Ideal Convergence: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, *ideal = do_gradient_descent(LR=0.5, epochs=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, *slow = do_gradient_descent(LR=0.005, epochs=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, *unstable = do_gradient_descent(LR=22, epochs=50) # mild instability\n",
    "_, *unstable = do_gradient_descent(LR=5, epochs=1e3)  # full instability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(unstable[1], \"r-\")\n",
    "ax2.plot(unstable[0], \"g-\")\n",
    "\n",
    "ax1.set_xlabel(\"Number of epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\", color=\"r\")\n",
    "ax2.set_ylabel(\"Loss\", color=\"g\")\n",
    "plt.title(\"Test Accuracy and Training Loss\")\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Boundary Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get points for [-5,5] X [-5,5]\n",
    "N = 100\n",
    "x = np.linspace(-5, 5, N)\n",
    "y = np.linspace(-5, 5, N)\n",
    "f1, f2 = np.meshgrid(x, y)\n",
    "# create (N X N, M) array for our predict function\n",
    "model_input = np.c_[f1.flatten(), f2.flatten()]\n",
    "\n",
    "if \"circles\" in npzfile.fid.name and augment_data:\n",
    "    model_input = make_nonlinear(model_input)\n",
    "\n",
    "if add_bias:\n",
    "    model_input = np.c_[model_input, np.ones([model_input.shape[0], 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, *_ = do_gradient_descent(LR=0.5, epochs=1e3)\n",
    "# create (N X N, 1) output\n",
    "predictions = predict(model_input, theta)\n",
    "# reshape to match our feature space\n",
    "predictions = predictions.squeeze().reshape(f1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = [\"blue\", \"red\"]\n",
    "\n",
    "# set colors for our data\n",
    "gt_colors = np.copy(y_test).astype(\"object\")\n",
    "gt_colors[gt_colors == 0] = colors[0]\n",
    "gt_colors[gt_colors == 1] = colors[1]\n",
    "gt_colors = gt_colors.ravel().tolist()\n",
    "plt.scatter(\n",
    "    X_test[:, 0], X_test[:, 1], marker=\"o\", c=gt_colors, s=25, edgecolor=\"k\", alpha=0.5\n",
    ")\n",
    "\n",
    "# get unique labels\n",
    "# colorbar_levels = list(np.unique(predictions.flatten()))\n",
    "colorbar_levels = [0, 0.5, 1]\n",
    "img = ax.contourf(f1, f2, predictions, levels=colorbar_levels, cmap=cm.bwr, alpha=0.75)\n",
    "plt.colorbar(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ones = len(y_test[y_test == 1])\n",
    "n_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_zeros = len(y_test[y_test == 0])\n",
    "n_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "777767a16c0aec6790b0fb66cfbacb4a2f697f61c7c4b53da01ea9aa6ebfd932"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
