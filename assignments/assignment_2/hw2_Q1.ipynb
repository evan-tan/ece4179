{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# face dataset\n",
    "\n",
    "the following class reads the face dataset and creates a torch dataset object for it. With this, you can easily \n",
    "use a dataloader to train your model. \n",
    "\n",
    "**1** Make sure that the file \"hw2_Q1.npy\" is located properly (in this example, it should be in the same folder as this notebook.\n",
    "\n",
    "**2** Note that the \"hw2_Q1.npy\" stores images in uint8 format. To use it for our purpose, we convert it to float32. You need to do the same for Q2 and Q3 of the assignment  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FaceData(Dataset):\n",
    "    def __init__(self, ray_tune=False):\n",
    "        # Ray Tune requires an absolute path\n",
    "        # go back 2 folders since ray goes 2 deeper\n",
    "        actual_cwd = str(Path.cwd().parents[1])\n",
    "        if not ray_tune:\n",
    "            actual_cwd = \".\"\n",
    "\n",
    "        self.images = np.load(f\"{actual_cwd}/data/hw2_Q1.npy\")\n",
    "        self.images = np.float32(self.images) / 255.0\n",
    "        self.images = self.images.reshape(-1, 64 * 64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # single index, shape: (1, 4096)\n",
    "        # multi-index, shape: (len(idx), 4096)\n",
    "        sample = self.images[idx, :]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how you can create a dataloader for the face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dataset = FaceData()\n",
    "tmp_loader = DataLoader(tmp_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = next(iter(tmp_loader))\n",
    "fig, ax_arr = plt.subplots(2, 4)\n",
    "for i in range(8):\n",
    "    img = image_batch[i].numpy()\n",
    "    ax_arr[i // 4, i % 4].imshow(img.reshape([64, 64]), cmap=\"gray\")\n",
    "    ax_arr[i // 4, i % 4].axis(\"off\")\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model and training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our neural network\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        Constructor for our SimpleAE,\n",
    "        where n should be 16 or 64\n",
    "        \"\"\"\n",
    "        super(AE, self).__init__()\n",
    "        # input -> fc1 -> ReLU -> fc2 -> output\n",
    "        self.fc1 = nn.Linear(4096, n)\n",
    "        self.fc2 = nn.Linear(n, 4096)\n",
    "\n",
    "        self._name = self.__class__.__name__ + \"_n{}\".format(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulating the training function to use with Ray Tune to identify the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \"\"\"The original training function has been modified in order to use Ray's Tune\"\"\"\n",
    "\n",
    "    logger = {\n",
    "        \"train\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"test\": np.zeros(config[\"num_epochs\"]),\n",
    "    }\n",
    "\n",
    "    #### LOAD DATA ####\n",
    "    # no test/validation set\n",
    "    train_data = FaceData(config[\"ray_tune_enabled\"])\n",
    "    # b_size = 16\n",
    "    b_size = config[\"batch_size\"]\n",
    "    n_workers = 4 * torch.cuda.device_count()\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=b_size,\n",
    "        num_workers=n_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    #### INSTANTIATE MODEL ####\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    net = AE(config[\"n\"]).to(device)\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    #### BEGIN TRAINING ####\n",
    "    start_time = time.time()\n",
    "    for j in range(config[\"num_epochs\"]):\n",
    "        ## START OF BATCH ##\n",
    "        train_loss = 0.0\n",
    "        train_steps = 0\n",
    "        for batch_id, data in enumerate(train_dataloader):\n",
    "            data = data.to(device)\n",
    "            prediction = net(data)\n",
    "\n",
    "            # there are no labels\n",
    "            loss = loss_function(prediction, data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            train_steps += 1\n",
    "        ## END OF BATCH ##\n",
    "\n",
    "        epoch_loss = train_loss / train_steps\n",
    "        # send current training result back to Tune\n",
    "        if config[\"ray_tune_enabled\"]:\n",
    "            tune.report(loss=(epoch_loss))\n",
    "\n",
    "        logger[\"train\"][j] = epoch_loss\n",
    "\n",
    "        if config[\"log_training\"] and (j + 1) % config[\"log_interval\"] == 0:\n",
    "            print(\n",
    "                f\"Epoch:{j+1}/{config['num_epochs']} \\\n",
    "                Train_Loss: {logger['train'][j]:.6f}\"\n",
    "            )\n",
    "\n",
    "        if config[\"save_model\"] and (j + 1) % config[\"save_interval\"] == 0:\n",
    "            checkpoint_num = str(j + 1).zfill(len(str(config[\"num_epochs\"])))\n",
    "            model_path = f\"./models/{net._name}_{checkpoint_num}.pt\"\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    print(f\"{config['num_epochs']} epochs took {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    if config[\"log_training\"]:\n",
    "        return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate folder to store our models\n",
    "!mkdir models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Tune using ASHA Scheduler to find ideal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run Tune for n = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # remove to make cell work\n",
    "search_space = {\n",
    "    \"n\": 16,\n",
    "    \"lr\": tune.loguniform(1e-6, 1e-1),\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "    \"log_training\": False,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "    \"save_interval\": 10,\n",
    "    \"num_epochs\": 200,\n",
    "    \"ray_tune_enabled\": True\n",
    "}\n",
    "# enable early stopping\n",
    "asha_scheduler = ASHAScheduler(max_t=200, grace_period=25)\n",
    "# number of samples to run\n",
    "n_samples = 20\n",
    "# run training with Tune\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    num_samples=n_samples,\n",
    "    config=search_space,\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    scheduler=asha_scheduler,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    local_dir=\"./\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run Tune for n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # remove to make cell work\n",
    "search_space = {\n",
    "    \"n\": 64,\n",
    "    \"lr\": tune.loguniform(1e-6, 1e-1),\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "    \"log_training\": False,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "    \"save_interval\": 10,\n",
    "    \"num_epochs\": 200,\n",
    "    \"ray_tune_enabled\": True\n",
    "}\n",
    "# enable early stopping\n",
    "asha_scheduler = ASHAScheduler(max_t=200, grace_period=25)\n",
    "# number of samples to run\n",
    "n_samples = 20\n",
    "# run training with Tune\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    num_samples=n_samples,\n",
    "    config=search_space,\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    scheduler=asha_scheduler,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    local_dir=\"./\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use ideal parameters from Tune runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model for n = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"n\": 16,\n",
    "    \"lr\": 9.33e-5,\n",
    "    \"batch_size\": 16,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "    \"save_interval\": 10,\n",
    "    \"num_epochs\": 200,\n",
    "    \"ray_tune_enabled\": False,\n",
    "}\n",
    "\n",
    "# run model training\n",
    "training_log_n16 = train_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model for n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"n\": 64,\n",
    "    \"lr\": 1.67e-4,\n",
    "    \"batch_size\": 64,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "    \"save_interval\": 10,\n",
    "    \"num_epochs\": 200,\n",
    "    \"ray_tune_enabled\": False,\n",
    "}\n",
    "\n",
    "# run model training\n",
    "training_log_n64 = train_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "all_logs = [training_log_n16, training_log_n64]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "epochs = model_config.get(\"num_epochs\")\n",
    "for i, log in enumerate(all_logs):\n",
    "    x_axis = np.linspace(1, epochs, epochs)\n",
    "    if i == 0:\n",
    "        label_str = r\"n = 16, $\\eta$ = 9.33e-5, batch_size = 16\"\n",
    "    elif i == 1:\n",
    "        label_str = r\"n = 64, $\\eta$ = 1.67e-4, batch_size = 64\"\n",
    "    ax.plot(x_axis, log.get(\"train\"), label=label_str)\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_title(\"ASD\")\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(16)\n",
    "ax.legend(loc=\"best\", prop={\"size\": 20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test our model on some outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_faces = 6\n",
    "sample = next(iter(tmp_loader))\n",
    "tmp_loader = DataLoader(FaceData(), batch_size=n_faces, shuffle=True)\n",
    "\n",
    "# instantiate models on CPU\n",
    "ae_n16 = AE(n=16)\n",
    "ae_n64 = AE(n=64)\n",
    "# load saved checkpoints for both models, taking model @ 200 epochs\n",
    "ae_n16.load_state_dict(torch.load(\"models/AE_n16_200.pt\"))\n",
    "ae_n64.load_state_dict(torch.load(\"models/AE_n64_200.pt\"))\n",
    "\n",
    "ae_n16.eval()\n",
    "ae_n64.eval()\n",
    "# run inference\n",
    "out_n16 = ae_n16(sample)\n",
    "out_n64 = ae_n64(sample)\n",
    "\n",
    "# visualization\n",
    "fig, ax = plt.subplots(3, n_faces)\n",
    "for k in range(n_faces):\n",
    "    ax[0, k].imshow(sample[k].reshape(64, 64), cmap=\"gray\")\n",
    "    with torch.no_grad():\n",
    "        ax[1, k].imshow(out_n16[k].reshape(64, 64), cmap=\"gray\")\n",
    "        ax[2, k].imshow(out_n64[k].reshape(64, 64), cmap=\"gray\")\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(n_faces):\n",
    "        # ax[i, j].set_aspect(\"equal\")\n",
    "        ax[i, j].axis(\"off\")\n",
    "\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the fc1 weights\n",
    "NOTE that this uses the saved weights so set `\"save_model\": True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 16, lr = 9.33e-5\n",
    "# n = 64, lr = 1.67e-4\n",
    "model_config = {\n",
    "    \"n\": 16,\n",
    "    \"lr\": 0.9,\n",
    "    \"batch_size\": 16,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"save_interval\": 10,\n",
    "    \"num_epochs\": 200,\n",
    "    \"ray_tune_enabled\": False,\n",
    "}\n",
    "log = train_model(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite previous sample\n",
    "sample = next(iter(tmp_loader))\n",
    "\n",
    "# parameter n for different models\n",
    "N = [16, 64, 256]\n",
    "save_interval = model_config.get(\"save_interval\")\n",
    "n_epochs = model_config.get(\"num_epochs\")\n",
    "n_models = n_epochs // save_interval\n",
    "\n",
    "for fc1_n in N:\n",
    "    # instantiate model\n",
    "    net = AE(fc1_n)\n",
    "    for k in range(n_models):\n",
    "        if k != 19:\n",
    "            continue\n",
    "        # load saved checkpoints inside loop\n",
    "        model = str((k + 1) * 10).zfill(len(str(n_epochs)))\n",
    "        model_path = f\"models/AE_n{fc1_n}_{model}.pt\"\n",
    "        net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # extract fc1 weights, shape=(16,4096) or (64,4096)\n",
    "            fc1_weights = net.fc1.weight + net.fc1.bias.unsqueeze(1)\n",
    "            # reshape for plotting\n",
    "            fc1_weights = fc1_weights.reshape(-1, 64, 64)\n",
    "\n",
    "            # autodetect based on n parameter in the network\n",
    "            # MUST BE SQUARE!!!!\n",
    "            L = np.sqrt(fc1_weights.shape[0]).astype(int)\n",
    "            fig, ax = plt.subplots(L, L)\n",
    "            for idx in range(fc1_weights.shape[0]):\n",
    "                # reshape for plotting\n",
    "                # img = fc1_weights[k].reshape(64, 64).cpu().detach().numpy()\n",
    "                ax[idx // L, idx % L].imshow(fc1_weights[idx], cmap=\"gray\")\n",
    "                ax[idx // L, idx % L].axis(\"off\")\n",
    "            fig.set_figheight(10)\n",
    "            fig.set_figwidth(20)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, n_faces)\n",
    "for k in range(n_faces):\n",
    "    ax[k].imshow(tmp_faces[k].reshape(64, 64), cmap=\"gray\")\n",
    "    ax[k].axis(\"off\")\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the weights of fc1 layer for net_n16\n",
    "fc1_n16 = ae_n16.fc1.weight + ae_n16.fc1.bias.unsqueeze(1)\n",
    "fc1_n16 = fc1_n16.reshape(-1, 64, 64).cpu().detach().numpy()\n",
    "L = np.sqrt(fc1_n16.shape[0]).astype(int)\n",
    "fig, ax = plt.subplots(L, L)\n",
    "for k in range(fc1_n16.shape[0]):\n",
    "    ax[k // L, k % L].imshow(fc1_n16[k], cmap=\"gray\")\n",
    "    ax[k // L, k % L].axis(\"off\")\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models for inference\n",
    "N = 16\n",
    "net = SimpleAE(N)\n",
    "\n",
    "for k in range(n_epochs // checkpoint_interval):\n",
    "    model = str((k + 1) * 10).zfill(len(str(n_epochs)))\n",
    "    model_path = f\"models/SimpleAE_n{N}_{model}.pt\"\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded {model_path}\")\n",
    "    net.eval()\n",
    "\n",
    "    # run inference\n",
    "    output = net(tmp_faces).to(device)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4)\n",
    "    for k in range(4):\n",
    "        img = output[k].reshape(64, 64).cpu().detach().numpy()\n",
    "        ax[k].imshow(img, cmap=\"gray\")\n",
    "        ax[k].axis(\"off\")\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(20)\n",
    "    plt.show()\n",
    "    plt.pause(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "\n",
    "output = ae_n64(tmp_faces.to(device))\n",
    "\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for k in range(8):\n",
    "    img = output[k].reshape(64, 64).cpu().detach().numpy()\n",
    "    ax[k // 4, k % 4].imshow(img.reshape(64, 64), cmap=\"gray\")\n",
    "    ax[k // 4, k % 4].axis(\"off\")\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net_n16.state_dict():\n",
    "    print(param_tensor, \"\\t\", net_n16.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ae_n16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ae_n16, (8, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "777767a16c0aec6790b0fb66cfbacb4a2f697f61c7c4b53da01ea9aa6ebfd932"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
