{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_workers = 4 * torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# face dataset\n",
    "\n",
    "the following class reads the face dataset and creates a torch dataset object for it. With this, you can easily \n",
    "use a dataloader to train your model. \n",
    "\n",
    "**1** Make sure that the file \"hw2_Q1.npy\" is located properly (in this example, it should be in the same folder as this notebook.\n",
    "\n",
    "**2** Note that the \"hw2_Q1.npy\" stores images in uint8 format. To use it for our purpose, we convert it to float32. You need to do the same for Q2 and Q3 of the assignment  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FaceData(Dataset):\n",
    "    def __init__(self, ray_tune=False):\n",
    "        # Ray Tune requires an absolute path\n",
    "        # go back 2 folders since ray goes 2 deeper\n",
    "        actual_cwd = str(Path.cwd().parents[1])\n",
    "        if not ray_tune:\n",
    "            actual_cwd = \".\"\n",
    "\n",
    "        self.images = np.load(f\"{actual_cwd}/data/hw2_Q1.npy\")\n",
    "        self.images = np.float32(self.images) / 255.0\n",
    "        self.images = self.images.reshape(-1, 64 * 64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # single index, shape: (1, 4096)\n",
    "        # multi-index, shape: (len(idx), 4096)\n",
    "        sample = self.images[idx, :]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how you can create a dataloader for the face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dataset = FaceData()\n",
    "tmp_loader = DataLoader(tmp_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = next(iter(tmp_loader))\n",
    "fig, ax_arr = plt.subplots(2, 4)\n",
    "for i in range(8):\n",
    "    img = image_batch[i].numpy()\n",
    "    ax_arr[i // 4, i % 4].imshow(img.reshape([64, 64]), cmap=\"gray\")\n",
    "    ax_arr[i // 4, i % 4].axis(\"off\")\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model and training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our neural network\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        Constructor for our SimpleAE,\n",
    "        where n should be 16 or 64\n",
    "        \"\"\"\n",
    "        super(AE, self).__init__()\n",
    "        # input -> fc1 -> ReLU -> fc2 -> output\n",
    "        self.fc1 = nn.Linear(4096, n)\n",
    "        self.fc2 = nn.Linear(n, 4096)\n",
    "\n",
    "        self._name = self.__class__.__name__ + \"_n{}\".format(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_log(log, model_config, select=False, save=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    if select:\n",
    "        # find min/max for criteria\n",
    "        selected = {}\n",
    "        for key in log:\n",
    "            if \"loss\" in key:\n",
    "                idx = np.argmin(log[key][9::10])\n",
    "                label = \"Min \"\n",
    "            elif \"acc\" in key:\n",
    "                idx = np.argmax(log[key][9::10])\n",
    "                label = \"Max \"\n",
    "            # 10 - 2000 epochs would be saved as 9 - 1999\n",
    "            # take every 10th epoch, determine a usable model\n",
    "            actual_idx = (idx + 1) * model_config[\"save_interval\"] - 1\n",
    "            selected[key] = actual_idx\n",
    "\n",
    "            print(key, actual_idx)\n",
    "            print(actual_idx, log.get(key)[actual_idx])\n",
    "\n",
    "            ax.plot(\n",
    "                actual_idx,\n",
    "                log.get(key)[actual_idx],\n",
    "                label=label + key,\n",
    "                markersize=16,\n",
    "                marker=\"X\",\n",
    "            )\n",
    "\n",
    "    epochs = model_config.get(\"num_epochs\")\n",
    "    x_axis = np.linspace(1, epochs, epochs)\n",
    "\n",
    "    ax.plot(x_axis, log.get(\"train_loss\"), label=\"Train Loss\")\n",
    "\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(16)\n",
    "\n",
    "    ax.legend(loc=\"best\", prop={\"size\": 12})\n",
    "    if save:\n",
    "        plt.savefig(f\"./LR_{model_config['lr']}_{model_config['num_epochs']}.jpg\")\n",
    "    plt.show()\n",
    "    if select:\n",
    "        return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(net, data_generator, loss_fn):\n",
    "    \"\"\"Function to easily test model on specified dataset\"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_loss, batch_steps = 0.0, 0\n",
    "        correct_pred, total_pred = 0, 0\n",
    "\n",
    "        for batch_id, (data, label) in enumerate(data_generator):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "            batch_loss += loss_fn(output, label).item()\n",
    "            batch_steps += 1\n",
    "\n",
    "            # indices where probability is maximum\n",
    "            _, val_pred = torch.max(output, 1)\n",
    "\n",
    "            correct_pred += (val_pred == label).sum().item()\n",
    "            total_pred += label.shape[0]\n",
    "\n",
    "        # average loss/acc across ALL batches\n",
    "        # i.e. ACROSS specified dataset\n",
    "        avg_loss = batch_loss / batch_steps\n",
    "        avg_acc = correct_pred / total_pred\n",
    "\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \"\"\"The original training function has been modified in order to use Ray's Tune\"\"\"\n",
    "\n",
    "    logger = {\n",
    "        \"train\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"test\": np.zeros(config[\"num_epochs\"]),\n",
    "    }\n",
    "\n",
    "    #### LOAD DATA ####\n",
    "    # no test/validation set\n",
    "    train_data = FaceData(config[\"ray_tune_enabled\"])\n",
    "    b_size = config[\"batch_size\"]\n",
    "    n_workers = 4 * torch.cuda.device_count()\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=b_size,\n",
    "        num_workers=n_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    #### INSTANTIATE MODEL ####\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    net = AE(config[\"n\"]).to(device)\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(\n",
    "        net.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    #### BEGIN TRAINING ####\n",
    "    start_time = time.time()\n",
    "    for j in range(config[\"num_epochs\"]):\n",
    "        ## START OF BATCH ##\n",
    "        train_loss = 0.0\n",
    "        train_steps = 0\n",
    "        for batch_id, data in enumerate(train_dataloader):\n",
    "            data = data.to(device)\n",
    "            prediction = net(data)\n",
    "\n",
    "            # there are no labels\n",
    "            loss = loss_function(prediction, data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "        ## END OF BATCH ##\n",
    "\n",
    "        epoch_loss = train_loss / train_steps\n",
    "        # send current training result back to Tune\n",
    "        if config[\"ray_tune_enabled\"]:\n",
    "            tune.report(loss=(epoch_loss))\n",
    "\n",
    "        logger[\"train\"][j] = epoch_loss\n",
    "\n",
    "        if config[\"log_training\"] and (j + 1) % config[\"log_interval\"] == 0:\n",
    "            print(\n",
    "                f\"Epoch:{j+1}/{config['num_epochs']} \\\n",
    "                Train Loss: {logger['train'][j]:.6f}\"\n",
    "            )\n",
    "\n",
    "        # make sure folder is created to place saved checkpoints\n",
    "        path = Path.cwd() / \"models\" / net._name\n",
    "        if not path.exists():\n",
    "            path.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "        if config[\"save_model\"] and (j + 1) % config[\"save_interval\"] == 0:\n",
    "            checkpoint_num = str(j + 1).zfill(len(str(config[\"num_epochs\"])))\n",
    "            model_path = f\"./models/{net._name}/{net._name}_{checkpoint_num}.pt\"\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    print(f\"{config['num_epochs']} epochs took {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    if config[\"log_training\"]:\n",
    "        return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate folder to store our models\n",
    "!mkdir models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Tune using ASHA Scheduler to find ideal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run Tune for n = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove to make cell work\n",
    "# search_space = {\n",
    "#     \"n\": 16,\n",
    "#     \"lr\": tune.loguniform(1e-6, 1e-1),\n",
    "#     \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "#     \"log_training\": False,\n",
    "#     \"log_interval\": 10,\n",
    "#     \"save_model\": False,\n",
    "#     \"save_interval\": 10,\n",
    "#     \"num_epochs\": 200,\n",
    "#     \"ray_tune_enabled\": True\n",
    "# }\n",
    "# # enable early stopping\n",
    "# asha_scheduler = ASHAScheduler(max_t=200, grace_period=25)\n",
    "# # number of samples to run\n",
    "# n_samples = 20\n",
    "# # run training with Tune\n",
    "# analysis = tune.run(\n",
    "#     train_model,\n",
    "#     num_samples=n_samples,\n",
    "#     config=search_space,\n",
    "#     resources_per_trial={\"gpu\": 1},\n",
    "#     scheduler=asha_scheduler,\n",
    "#     metric=\"loss\",\n",
    "#     mode=\"min\",\n",
    "#     local_dir=\"./\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run Tune for n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False  # remove to make cell work\n",
    "# search_space = {\n",
    "#     \"n\": 64,\n",
    "#     \"lr\": tune.loguniform(1e-6, 1e-1),\n",
    "#     \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "#     \"log_training\": False,\n",
    "#     \"log_interval\": 10,\n",
    "#     \"save_model\": False,\n",
    "#     \"save_interval\": 10,\n",
    "#     \"num_epochs\": 200,\n",
    "#     \"ray_tune_enabled\": True\n",
    "# }\n",
    "# # enable early stopping\n",
    "# asha_scheduler = ASHAScheduler(max_t=200, grace_period=25)\n",
    "# # number of samples to run\n",
    "# n_samples = 20\n",
    "# # run training with Tune\n",
    "# analysis = tune.run(\n",
    "#     train_model,\n",
    "#     num_samples=n_samples,\n",
    "#     config=search_space,\n",
    "#     resources_per_trial={\"gpu\": 1},\n",
    "#     scheduler=asha_scheduler,\n",
    "#     metric=\"loss\",\n",
    "#     mode=\"min\",\n",
    "#     local_dir=\"./\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model for n = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"n\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"batch_size\": 64,\n",
    "    \"weight_decay\": 2.5e-5,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"save_interval\": 10,\n",
    "    \"num_epochs\": 300,\n",
    "    \"ray_tune_enabled\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run model training\n",
    "# training_log_n16 = train_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model for n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"n\": 64,\n",
    "    \"lr\": 1e-4,\n",
    "    \"batch_size\": 64,\n",
    "    \"weight_decay\": 5e-5,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "    \"save_interval\": 10,\n",
    "    \"num_epochs\": 300,\n",
    "    \"ray_tune_enabled\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run model training\n",
    "# training_log_n64 = train_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the results\n",
    "# all_logs = [training_log_n16, training_log_n64]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# epochs = model_config.get(\"num_epochs\")\n",
    "# for i, log in enumerate(all_logs):\n",
    "#     x_axis = np.linspace(1, epochs, epochs)\n",
    "#     if i == 0:\n",
    "#         label_str = r\"n = 16, $\\eta$ = 1e-4, batch_size = 64\"\n",
    "#     elif i == 1:\n",
    "#         label_str = r\"n = 64, $\\eta$ = 1e-4, batch_size = 64\"\n",
    "#     ax.plot(x_axis, log.get(\"train\"), label=label_str)\n",
    "# ax.set_ylabel(\"Loss\")\n",
    "# ax.set_xlabel(\"Epochs\")\n",
    "# ax.set_title(\"ASD\")\n",
    "# fig.set_figheight(10)\n",
    "# fig.set_figwidth(16)\n",
    "# ax.legend(loc=\"best\", prop={\"size\": 20})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test our model on some outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_faces = 6\n",
    "sample = next(iter(tmp_loader))\n",
    "tmp_loader = DataLoader(FaceData(), batch_size=n_faces, shuffle=True)\n",
    "\n",
    "# instantiate models on CPU\n",
    "ae_n16 = AE(n=16)\n",
    "ae_n64 = AE(n=64)\n",
    "# load saved checkpoints for both models, taking model @ 300 epochs\n",
    "ae_n16.load_state_dict(torch.load(f\"models/{ae_n16._name}/{ae_n16._name}_300.pt\"))\n",
    "ae_n64.load_state_dict(torch.load(f\"models/{ae_n64._name}/{ae_n64._name}_300.pt\"))\n",
    "\n",
    "ae_n16.eval()\n",
    "ae_n64.eval()\n",
    "# run inference\n",
    "out_n16 = ae_n16(sample)\n",
    "out_n64 = ae_n64(sample)\n",
    "\n",
    "# visualization\n",
    "fig, ax = plt.subplots(3, n_faces)\n",
    "for k in range(n_faces):\n",
    "    ax[0, k].imshow(sample[k].reshape(64, 64), cmap=\"gray\")\n",
    "    with torch.no_grad():\n",
    "        ax[1, k].imshow(out_n16[k].reshape(64, 64), cmap=\"gray\")\n",
    "        ax[2, k].imshow(out_n64[k].reshape(64, 64), cmap=\"gray\")\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(n_faces):\n",
    "        # ax[i, j].set_aspect(\"equal\")\n",
    "        ax[i, j].axis(\"off\")\n",
    "\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the fc1 weights\n",
    "NOTE that this uses the saved weights so set `\"save_model\": True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter n for different models\n",
    "N = [16, 64]\n",
    "save_interval = model_config.get(\"save_interval\")\n",
    "n_epochs = model_config.get(\"num_epochs\")\n",
    "n_models = n_epochs // save_interval\n",
    "\n",
    "for fc1_n in N:\n",
    "    # instantiate model\n",
    "    net = AE(fc1_n)\n",
    "    for k in range(n_models):\n",
    "        if k < (n_models - 1):\n",
    "            continue\n",
    "        # load saved checkpoints inside loop\n",
    "        model = str((k + 1) * 10).zfill(len(str(n_epochs)))\n",
    "        model_path = f\"models/{net._name}/{net._name}_{model}.pt\"\n",
    "        net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # extract fc1 weights, shape=(16,4096) or (64,4096)\n",
    "            fc1_weights = net.fc1.weight + net.fc1.bias.unsqueeze(1)\n",
    "            # reshape for plotting\n",
    "            fc1_weights = fc1_weights.reshape(-1, 64, 64)\n",
    "\n",
    "            # autodetect based on n parameter in the network\n",
    "            # MUST BE SQUARE!!!!\n",
    "            L = np.sqrt(fc1_weights.shape[0]).astype(int)\n",
    "            fig, ax = plt.subplots(L, L)\n",
    "            for idx in range(fc1_weights.shape[0]):\n",
    "                # reshape for plotting\n",
    "                # img = fc1_weights[k].reshape(64, 64).cpu().detach().numpy()\n",
    "                ax[idx // L, idx % L].imshow(fc1_weights[idx], cmap=\"gray\")\n",
    "                ax[idx // L, idx % L].axis(\"off\")\n",
    "            fig.set_figheight(10)\n",
    "            fig.set_figwidth(10)\n",
    "            plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy contaminated faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_faces = 6\n",
    "sample = next(iter(tmp_loader))\n",
    "tmp_loader = DataLoader(FaceData(), batch_size=n_faces, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate models on CPU\n",
    "ae_n64 = AE(n=64)\n",
    "# load saved checkpoints for both models, taking model @ 300 epochs\n",
    "ae_n64.load_state_dict(torch.load(f\"models/{ae_n64._name}/{ae_n64._name}_300.pt\"))\n",
    "\n",
    "ae_n64.eval()\n",
    "# run inference\n",
    "noise = np.random.uniform(low=-0.4, high=0.4, size=(n_faces, 4096))\n",
    "low_noisy_faces = np.clip(sample + noise, 0, 1).float()\n",
    "noise = np.random.uniform(low=-0.9, high=0.9, size=(n_faces, 4096))\n",
    "high_noisy_faces = np.clip(sample + noise, 0, 1).float()\n",
    "\n",
    "out_clean = ae_n64(sample)\n",
    "out_dirty = ae_n64(low_noisy_faces)\n",
    "out_vdirty = ae_n64(high_noisy_faces)\n",
    "\n",
    "# visualization\n",
    "fig, ax = plt.subplots(6, n_faces)\n",
    "for k in range(n_faces):\n",
    "    ax[0, k].imshow(sample[k].reshape(64, 64), cmap=\"gray\")\n",
    "    ax[1, k].imshow(low_noisy_faces[k].reshape(64, 64), cmap=\"gray\")\n",
    "    ax[2, k].imshow(high_noisy_faces[k].reshape(64, 64), cmap=\"gray\")\n",
    "    with torch.no_grad():\n",
    "        ax[3, k].imshow(out_clean[k].reshape(64, 64), cmap=\"gray\")\n",
    "        ax[4, k].imshow(out_dirty[k].reshape(64, 64), cmap=\"gray\")\n",
    "        ax[5, k].imshow(out_vdirty[k].reshape(64, 64), cmap=\"gray\")\n",
    "for i in range(len(ax)):\n",
    "    for j in range(n_faces):\n",
    "        # ax[i, j].set_aspect(\"equal\")\n",
    "        ax[i, j].axis(\"off\")\n",
    "\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenfaces using SVD\n",
    "https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_eigenfaces.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "777767a16c0aec6790b0fb66cfbacb4a2f697f61c7c4b53da01ea9aa6ebfd932"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
