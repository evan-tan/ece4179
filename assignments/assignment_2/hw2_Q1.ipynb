{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## face dataset\n",
    "\n",
    "the following class reads the face dataset and creates a torch dataset object for it. With this, you can easily \n",
    "use a dataloader to train your model. \n",
    "\n",
    "**1** Make sure that the file \"hw2_Q1.npy\" is located properly (in this example, it should be in teh same folder as this notebook.\n",
    "\n",
    "**2** Note that the \"hw2_Q1.npy\" stores images in uint8 format. To use it for our purpose, we convert it to float32. You need to do the same for Q2 and Q3 of the assignment  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceData(Dataset):\n",
    "    def __init__(self):\n",
    "        self.images = np.load('./data/hw2_Q1.npy')\n",
    "        self.images = np.float32(self.images)/255.0\n",
    "        self.images = self.images.reshape(-1,64*64)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "   \n",
    "        sample = self.images[idx,:]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how you can create a dataloader for the face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dataset = FaceData()\n",
    "trainloader = DataLoader(face_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = next(iter(trainloader))\n",
    "fig, ax_arr = plt.subplots(2, 4)\n",
    "for tmpC1 in range(8):    \n",
    "    img = image_batch[tmpC1].numpy()\n",
    "    ax_arr[tmpC1//4, tmpC1 % 4].imshow(img.reshape([64,64]), cmap = 'gray')\n",
    "    ax_arr[tmpC1//4, tmpC1 % 4].axis('off')    \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
