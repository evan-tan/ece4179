{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader Example\n",
    "\n",
    "the following class reads the data for the third assignment and creates a torch dataset object for it. With this, you can easily use a dataloader to train your model. \n",
    "\n",
    "Due to size limit on moodle, the data for this assignment should be obtained from \n",
    "\n",
    "https://drive.google.com/file/d/1khzPamThzWScipEfMmOPevtfWV7Tx6UL/view?usp=sharing\n",
    "\n",
    "\n",
    "Make sure that the file \"hw3.npz\" is located properly (in this example, it should be in the same folder as this notebook).\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STLData(Dataset):\n",
    "    def __init__(self, mode=\"\", transform=None):\n",
    "        data = np.load(\"hw3.npz\")\n",
    "        if \"train\" in mode:\n",
    "            # trainloader\n",
    "            self.images = data[\"arr_0\"]\n",
    "            self.labels = data[\"arr_1\"]\n",
    "        elif \"val\" in mode:\n",
    "            # valloader\n",
    "            self.images = data[\"arr_2\"]\n",
    "            self.labels = data[\"arr_3\"]\n",
    "        elif \"test\" in mode:\n",
    "            # testloader\n",
    "            self.images = data[\"arr_4\"]\n",
    "            self.labels = data[\"arr_5\"]\n",
    "        else:\n",
    "            raise ValueError(\"mode should be 'train', 'val' or 'test'\")\n",
    "\n",
    "        # scale values from 0-255 to 0-1\n",
    "        self.images = np.float32(self.images) / 255.0\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = self.images[idx, :]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how you can create a dataloader. \n",
    "First read the data. Note that the STL10 class can work with torchvision.transforms that are required in HW3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modified STLData class\n",
    "train_set = STLData(\"train\")\n",
    "val_set = STLData(\"val\")\n",
    "test_set = STLData(\"test\")\n",
    "\n",
    "batch_size = 100\n",
    "n_workers = 0 * multiprocessing.cpu_count()\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, num_workers=n_workers\n",
    ")\n",
    "image_batch, labels = next(iter(trainloader))\n",
    "\n",
    "# # order tensor properly since no T.Tensor() called in STLData\n",
    "if trainloader.dataset.transform is None:\n",
    "    image_batch = image_batch.permute(0, 3, 1, 2)\n",
    "\n",
    "fig, ax_arr = plt.subplots(2, 4)\n",
    "for i in range(8):\n",
    "    img = (image_batch[i]).permute(1, 2, 0)\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax_arr[row, col].imshow(img)\n",
    "    # ax_arr[i // 4, i % 4].axis(\"off\")\n",
    "    ax_arr[row, col].axes.get_yaxis().set_visible(False)\n",
    "    ax_arr[row, col].set_xlabel(labels[i].item())\n",
    "    ax_arr[row, col].set_xticklabels([])\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(10)\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a batchsize of 100, you can have a dataloader as follows for your training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class labels for STL dataset\n",
    "class_labels = [\n",
    "    \"airplane\",\n",
    "    \"bird\",\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"monkey\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def un_normalize(img, mean, std):\n",
    "    \"\"\"Un-normalize a NORMALIZED IMAGE given mean and std, as lists of 3 elements\"\"\"\n",
    "    mean, std = torch.Tensor(mean), torch.Tensor(std)\n",
    "\n",
    "    # change from (3,) to (1,3,1,1) for broadcasting\n",
    "    mean, std = mean.unsqueeze(1).T, std.unsqueeze(1).T\n",
    "    mean = mean.unsqueeze(2).unsqueeze(3)\n",
    "    std = std.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "    return img.mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def order_tensor(t_: torch.Tensor):\n",
    "    \"\"\"Ensure proper order of tensor dims since T.ToTensor() is inconsistent\"\"\"\n",
    "\n",
    "    # i.e. (B,H,W,C) -> (B,C,H,W)\n",
    "    if t_.ndim == 4:\n",
    "        h, w, c = t_.shape[1:4]\n",
    "        if c < h or c < w:\n",
    "            return t_.permute(0, 3, 1, 2).contiguous()\n",
    "        else:\n",
    "            return t_\n",
    "\n",
    "    # (H,W,C) -> (C,H,W)\n",
    "    elif t_.ndim == 3:\n",
    "        h, w, c = t_.shape[0:3]\n",
    "        if c < h or c < w:\n",
    "            return t_.permute(2, 0, 1).contiguous()\n",
    "        else:\n",
    "            return t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_log(log, model_config, save=False, select=True):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    fig.set_figheight(7.5)\n",
    "    fig.set_figwidth(12)\n",
    "    # use ax1 for loss, ax2 for accuracy\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    epochs = model_config.get(\"num_epochs\")\n",
    "    x_axis = np.linspace(1, epochs, epochs)\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, len(log))))\n",
    "    # storage for all max/min values based on keys\n",
    "    selected = dict.fromkeys(log)\n",
    "\n",
    "    count = 0\n",
    "    for key, values in log.items():\n",
    "        c = next(color)\n",
    "        key_str = key.replace(\"_\", \" \").title()\n",
    "        # plot data\n",
    "        if \"loss\" in key:\n",
    "            ax1.plot(x_axis, values, color=c, label=key_str)\n",
    "        elif \"acc\" in key:\n",
    "            ax2.plot(x_axis, values, color=c, label=key_str)\n",
    "        if select:\n",
    "            if \"loss\" in key:\n",
    "                # search for min\n",
    "                x = np.argmin(values) + 1\n",
    "                y = np.amin(values)\n",
    "                ax1.plot(\n",
    "                    x,\n",
    "                    y,\n",
    "                    color=c,\n",
    "                    label=f\"Min. {key}\",\n",
    "                    markersize=16,\n",
    "                    marker=\"x\",\n",
    "                )\n",
    "            elif \"acc\" in key:\n",
    "                # search for max\n",
    "                x = np.argmax(log[key]) + 1\n",
    "                y = np.amax(log[key])\n",
    "                ax2.plot(\n",
    "                    x,\n",
    "                    y,\n",
    "                    color=c,\n",
    "                    label=f\"Max. {key}\",\n",
    "                    markersize=16,\n",
    "                    marker=\"x\",\n",
    "                )\n",
    "            # save values in dict\n",
    "            # format: (epoch id, data value)\n",
    "            selected[key] = (x, y)\n",
    "        count += 1\n",
    "\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.set_xlabel(\"Number of Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy (%)\")\n",
    "\n",
    "    # 0 = 'best', 7 = 'center right'\n",
    "    fig.legend(loc=7, bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f\"./LR_{model_config['lr']}_{model_config['num_epochs']}.jpg\")\n",
    "\n",
    "    plt.title(\n",
    "        f\"{model_cfg['model']._name} Learning Rate={str(model_cfg['lr'])} Batch Size={(model_cfg['batch_size'])} Max Val Acc={selected['val_acc'][1]} @ Epoch {selected['val_acc'][0]}\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    if select:\n",
    "        return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_model(net, data_generator, loss_fn, transform=None):\n",
    "    \"\"\"Function to easily test model on specified dataset\"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    net.eval()\n",
    "\n",
    "    batch_loss, batch_steps = 0.0, 0\n",
    "    correct_pred, total_pred = 0, 0\n",
    "\n",
    "    for batch_id, (data, label) in enumerate(data_generator):\n",
    "        data, label = data.to(device), label.long().to(device)\n",
    "\n",
    "        if data_generator.dataset.transform is None:\n",
    "            data = order_tensor(data)\n",
    "        if transform is not None:\n",
    "            data = transform(data.cuda())\n",
    "\n",
    "        output = net(data)\n",
    "        batch_loss += loss_fn(output, label).item()\n",
    "        batch_steps += 1\n",
    "\n",
    "        # indices where probability is maximum\n",
    "        _, pred_label = torch.max(output, 1)\n",
    "        correct_pred += (pred_label == label).sum().item()\n",
    "        total_pred += label.shape[0]\n",
    "\n",
    "    # average loss/acc across ALL batches\n",
    "    # i.e. ACROSS specified dataset\n",
    "    avg_loss = batch_loss / batch_steps\n",
    "    avg_acc = correct_pred / total_pred\n",
    "\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    n_workers = 0 * torch.cuda.device_count()\n",
    "\n",
    "    logger = {\n",
    "        \"train_loss\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"val_loss\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"train_acc\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"val_acc\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"test_acc\": np.zeros(config[\"num_epochs\"]),\n",
    "    }\n",
    "\n",
    "    #### LOAD DATA ####\n",
    "    b_size = config[\"batch_size\"]\n",
    "\n",
    "    train_transform = config.get(\"train_transform\")\n",
    "    val_transform = config.get(\"val_transform\")\n",
    "    test_transform = config.get(\"test_transform\")\n",
    "\n",
    "    train_data = STLData(\"train\")\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=b_size,\n",
    "        num_workers=n_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    val_data = STLData(\"val\")\n",
    "    val_dataloader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=b_size,\n",
    "        num_workers=n_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    test_data = STLData(\"test\")\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=b_size,\n",
    "        num_workers=n_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    #### INSTANTIATE MODEL ####\n",
    "    net = config[\"model\"].to(device)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    if \"Adam\" in config[\"optimizer\"]:\n",
    "        optimizer = optim.Adam(\n",
    "            net.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "    elif \"SGD\" in config[\"optimizer\"]:\n",
    "        optimizer = optim.SGD(\n",
    "            net.parameters(),\n",
    "            lr=config[\"lr\"],\n",
    "            momentum=config[\"momentum\"],\n",
    "            weight_decay=config[\"weight_decay\"],\n",
    "        )\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    # TODO: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html\n",
    "    # https://spell.ml/blog/lr-schedulers-and-adaptive-optimizers-YHmwMhAAACYADm6F\n",
    "    if config[\"lr_scheduler\"]:\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \"max\", 0.5, patience=config[\"num_epochs\"] // 10, verbose=True\n",
    "        )\n",
    "\n",
    "    #### BEGIN TRAINING ####\n",
    "    start_time = time.time()\n",
    "    best_val_acc = 0\n",
    "    for j in range(config[\"num_epochs\"]):\n",
    "        ## START OF EPOCH ##\n",
    "        train_loss, train_steps = 0.0, 0\n",
    "        net.train()\n",
    "        for batch_id, (data, label) in enumerate(train_dataloader):\n",
    "            data, label = data.to(device), label.long().to(device)\n",
    "\n",
    "            if train_dataloader.dataset.transform is None:\n",
    "                data = order_tensor(data)\n",
    "            if train_transform is not None:\n",
    "                data = train_transform(data.cuda())\n",
    "\n",
    "            # forwardfacecolor=fig.get_facecolor()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = net(data)\n",
    "                loss = loss_function(output, label)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "\n",
    "        ## END OF EPOCH ##\n",
    "\n",
    "        # average training loss for 1 epoch\n",
    "        train_loss /= train_steps\n",
    "\n",
    "        # test model on validation dataset\n",
    "        _, train_acc = test_model(net, train_dataloader, loss_function, train_transform)\n",
    "        val_loss, val_acc = test_model(\n",
    "            net, val_dataloader, loss_function, val_transform\n",
    "        )\n",
    "        _, test_acc = test_model(net, test_dataloader, loss_function, test_transform)\n",
    "\n",
    "        if config[\"lr_scheduler\"]:\n",
    "            scheduler.step(val_acc)\n",
    "\n",
    "        logger[\"train_loss\"][j] = train_loss\n",
    "        logger[\"val_loss\"][j] = val_loss\n",
    "        logger[\"train_acc\"][j] = train_acc\n",
    "        logger[\"val_acc\"][j] = val_acc\n",
    "        logger[\"test_acc\"][j] = test_acc\n",
    "\n",
    "        if config[\"log_training\"] and (j + 1) % config[\"log_interval\"] == 0:\n",
    "            print(\n",
    "                f\"Epoch:{j+1}/{config['num_epochs']}\",\n",
    "                f\"Train Loss: {logger['train_loss'][j]:.4f}\",\n",
    "                f\"Train Acc: {logger['train_acc'][j]:.4f}\",\n",
    "                f\"Val Loss: {logger['val_loss'][j]:.4f}\",\n",
    "                f\"Val Acc: {logger['val_acc'][j]:.4f}\",\n",
    "                f\"Test Acc: {logger['test_acc'][j]:.4f}\",\n",
    "            )\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            if config[\"save_model\"]:\n",
    "                # make sure folder is created to place saved checkpoints\n",
    "                path = Path.cwd() / \"models\" / net._name\n",
    "                if not path.exists():\n",
    "                    path.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "                # pad with appropriate number of zeros i.e. epoch 10 named as 010\n",
    "                checkpoint_num = str(j + 1).zfill(len(str(config[\"num_epochs\"])))\n",
    "                model_path = f\"./models/{net._name}/{net._name}_{checkpoint_num}.pt\"\n",
    "                torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    print(f\"{config['num_epochs']} epochs took {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    if config[\"log_training\"]:\n",
    "        return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_model_outputs(net, data_generator):\n",
    "    images = []  # (2000,)\n",
    "    labels = []  # (2000,)\n",
    "    # probability from softmax\n",
    "    confidence = []  # (2000,10)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        # loop through val dataset, collect all scores per class\n",
    "        for batch_id, (data, label) in enumerate(data_generator):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "\n",
    "            if data_generator.dataset.transform is None:\n",
    "                data = order_tensor(data)\n",
    "\n",
    "            output = net(data)\n",
    "            # apply softmax\n",
    "            probs = F.softmax(output, dim=1)\n",
    "\n",
    "            images += data\n",
    "            labels += label\n",
    "            confidence += probs\n",
    "\n",
    "    # convert lists of tensors to single tensor and overwrite variables\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.stack(labels)  # torch.Tensor(labels) also works\n",
    "    confidence = torch.stack(confidence)\n",
    "\n",
    "    return labels, confidence, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topk_by_class(net, dataloader, n_img, correct=True):\n",
    "    \"\"\"Return Top K images by confidence of prediction by class\"\"\"\n",
    "\n",
    "    labels, confidence, images = store_model_outputs(net, dataloader)\n",
    "\n",
    "    # find correct labels indices\n",
    "    idx = confidence.argmax(dim=1) == labels\n",
    "    if correct != True:\n",
    "        idx = ~idx  # jank bitwise complement\n",
    "\n",
    "    images = images[idx]\n",
    "    labels = labels[idx]\n",
    "    confidence = confidence[idx]\n",
    "\n",
    "    display_img = []\n",
    "    for j in range(confidence.shape[1]):\n",
    "        top_n_idx = torch.argsort(confidence[:, j], descending=True)[:n_img]\n",
    "        display_img += images[top_n_idx]\n",
    "\n",
    "    display_img = torch.stack(display_img).cpu()\n",
    "    return display_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_model_outputs(net, dataloader, correct=True):\n",
    "    \"\"\"Visualize model's top 5 images for each class on val dataset, defaults to correct predictions\"\"\"\n",
    "    num_img = 5\n",
    "\n",
    "    display_img = get_topk_by_class(net, dataloader, num_img, correct)\n",
    "    out = torchvision.utils.make_grid(display_img, nrow=num_img, padding=0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 20))\n",
    "    ax.imshow(out.permute(1, 2, 0), interpolation=\"nearest\", aspect=\"auto\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "\n",
    "    # adding class labels to y-axis\n",
    "    # appropriately space labels\n",
    "    offset = int(display_img.shape[2] / 2)\n",
    "    max_dim = int(display_img.shape[0] / num_img * display_img.shape[2])\n",
    "    spacing = int(display_img.shape[2])\n",
    "    yticks = [i for i in range(0 + offset, max_dim, spacing)]\n",
    "\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(class_labels)\n",
    "    mode_str = \"Correct\" if correct else \"Wrong\"\n",
    "    ax.set_title(\n",
    "        f\"Visualizing Top {num_img} {mode_str} image predictions for each class\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_confusion_matrix(\n",
    "    net,\n",
    "    data_generator,\n",
    "    labels,\n",
    "):\n",
    "    \"\"\"Create confusion matrix based for a given dataset and respective labels\"\"\"\n",
    "    true_labels, confidence, _ = store_model_outputs(net, data_generator)\n",
    "    pred_labels = confidence.argmax(dim=1).cpu()\n",
    "    true_labels = true_labels.cpu()\n",
    "\n",
    "    pred_labels = confidence.argmax(1)\n",
    "    n_classes = confidence.shape[1]\n",
    "    cm = np.zeros((n_classes, n_classes))\n",
    "    for i, val in enumerate(confidence):\n",
    "        cm[true_labels[i], pred_labels[i]] += 1\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.figure(figsize=(11, 8))\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\".0f\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.ylabel(\"True label\", rotation=0)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "    if type(data_generator) == DataLoader:\n",
    "        if len(data_generator.dataset) == len(STLData(\"test\")):\n",
    "            dataset_str = \"Test\"\n",
    "        elif len(data_generator.dataset) == len(STLData(\"train\")):\n",
    "            dataset_str = \"Train\"\n",
    "        elif len(data_generator.dataset) == len(STLData(\"val\")):\n",
    "            dataset_str = \"Validation\"\n",
    "\n",
    "    plt.title(f\"Confusion Matrix for {dataset_str} Dataset\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_mean_stdv1(mode=\"\"):\n",
    "#     assert mode == \"train\" or mode == \"val\" or mode == \"test\"\n",
    "#     dataset = STLData(mode)\n",
    "#     dataloader = DataLoader(\n",
    "#         dataset,\n",
    "#         batch_size=len(dataset),  # LMAOOOOOOOOOOOOOOOOOOOOO\n",
    "#         num_workers=0,\n",
    "#         shuffle=False,\n",
    "#         pin_memory=False,\n",
    "#     )\n",
    "\n",
    "#     # this runs a single time\n",
    "#     for _, (data, _) in enumerate(dataloader):\n",
    "#         if dataloader.dataset.transform is None:\n",
    "#             data = order_tensor(data)\n",
    "\n",
    "#         data = data.to(\"cpu\")\n",
    "#         # (B,C,H,W) -> (C,B,H,W) -> (C, B*H*W)\n",
    "#         data = data.permute(1, 0, 2, 3).flatten(start_dim=1)\n",
    "#         # mean or std dev across channels\n",
    "#         mean = data.mean(1).tolist()\n",
    "#         std = data.std(1).tolist()\n",
    "\n",
    "#     return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean_std(mode=\"\"):\n",
    "    assert mode == \"train\" or mode == \"val\" or mode == \"test\"\n",
    "    dataset = STLData(mode)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=512,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    mean, std = 0, 0\n",
    "    n_samples = 0\n",
    "    for _, (data, _) in enumerate(dataloader):\n",
    "        if dataloader.dataset.transform is None:\n",
    "            data = order_tensor(data)\n",
    "        data = data.flatten(2).to(\"cpu\")\n",
    "        # take across each channel\n",
    "        # dims=(B,C,H*W)\n",
    "        # calculate mean/std of each image\n",
    "        # then sum across batch\n",
    "        mean += data.mean(dim=2).sum(dim=0)\n",
    "        std += data.std(dim=2).sum(dim=0)\n",
    "        n_samples += data.shape[0]\n",
    "\n",
    "    mean /= n_samples\n",
    "    std /= n_samples\n",
    "\n",
    "    return mean.tolist(), std.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def occlusion_single_img(net, img, true_label, kernel: tuple, stride: int):\n",
    "    \"\"\"Perform Occlusion Sensitivity on a single img\"\"\"\n",
    "    if img.ndim == 4:\n",
    "        H, W = img.shape[2:4]\n",
    "    elif img.ndim == 3:\n",
    "        H, W = img.shape[1:3]\n",
    "\n",
    "    # determine output dimensions\n",
    "    H_out = int(np.floor((W - kernel[0]) / stride) + 1)\n",
    "    W_out = int(np.floor((H - kernel[1]) / stride) + 1)\n",
    "    heatmap = torch.zeros((H_out, W_out))\n",
    "\n",
    "    for i in range(H_out):\n",
    "        for j in range(W_out):\n",
    "            img_mod = T.functional.erase(\n",
    "                img, i * stride, j * stride, kernel[0], kernel[1], v=0\n",
    "            )\n",
    "\n",
    "            # run inference\n",
    "            net.eval()\n",
    "            output = net(img_mod)\n",
    "            # apply softmax\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            # setting the heatmap location to probability value\n",
    "            if torch.is_tensor(true_label):\n",
    "                heatmap[i, j] = probs.squeeze()[true_label.item()].item()\n",
    "            else:\n",
    "                # when true_label is a str\n",
    "                heatmap[i, j] = probs.squeeze()[true_label].item()\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ShallowCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShallowCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShallowCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, (7, 7), stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(96, 64, (5, 5), stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(64, 128, (3, 3), stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(1152, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._name = self.__class__.__name__\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # flatten all dimensions except batch\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shallow_net = ShallowCNN().to(device)\n",
    "model_cfg = {\n",
    "    \"model\": shallow_net,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"momentum\": 0,  # only for SGD\n",
    "    \"weight_decay\": 0,\n",
    "    \"lr\": 1e-4,\n",
    "    \"lr_scheduler\": False,\n",
    "    \"batch_size\": 128,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"num_epochs\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_shallow = train_model(model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_log(log_shallow, model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shallow_net = ShallowCNN().to(device)\n",
    "shallow_net.eval()\n",
    "# select 032.pt\n",
    "model_path = f\"models/{shallow_net._name}/select/{shallow_net._name}_032.pt\"\n",
    "shallow_net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\"),\n",
    "    batch_size=256,\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "_, test_acc = test_model(shallow_net, test_dataloader, nn.CrossEntropyLoss())\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(\n",
    "    STLData(\"val\"),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correct images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_model_outputs(shallow_net, val_dataloader, correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrong images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_model_outputs(shallow_net, val_dataloader, correct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    STLData(\"train\"),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    ")\n",
    "make_confusion_matrix(shallow_net, train_dataloader, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(\n",
    "    STLData(\"val\"),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "make_confusion_matrix(shallow_net, val_dataloader, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\"),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "make_confusion_matrix(shallow_net, test_dataloader, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# DeepCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "\n",
    "        self.blocks = self._build_blocks()\n",
    "        # global average pooling\n",
    "        # since the output of our conv blocks is (6,6)\n",
    "        self.gap = nn.AvgPool2d(kernel_size=6, stride=1)\n",
    "        self.fc1 = nn.Linear(192, 10)\n",
    "\n",
    "        self._name = self.__class__.__name__\n",
    "\n",
    "    def _build_blocks(self):\n",
    "        conv_blk_dims = [3, 32, 64, 128, 192]\n",
    "        blocks_list = []\n",
    "        for i in range(len(conv_blk_dims) - 1):\n",
    "            conv_block = self._create_conv_block(conv_blk_dims[i], conv_blk_dims[i + 1])\n",
    "            named_block = (f\"Conv-Blk-{i+1}\", conv_block)\n",
    "            # blocks_list.append(conv_block)\n",
    "            blocks_list.append(named_block)\n",
    "\n",
    "        # return nn.Sequential(*blocks_list)\n",
    "        return nn.Sequential(OrderedDict(blocks_list))\n",
    "\n",
    "    def _create_conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Create conv_block based on in/out channels\"\"\"\n",
    "        conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, (3, 3), stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, (1, 1), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, (3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        return conv_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        x = self.gap(x)\n",
    "        # flatten all dimensions except batch\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(DeepCNN())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## No transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_net = DeepCNN().to(device)\n",
    "\n",
    "model_cfg = {\n",
    "    \"model\": deep_net,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"momentum\": 0.9,  # only for SGD\n",
    "    \"weight_decay\": 0,\n",
    "    \"lr\": 2.5e-4,\n",
    "    \"lr_scheduler\": True,\n",
    "    \"batch_size\": 128,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"num_epochs\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_deep = train_model(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_log(log_deep, model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_net = DeepCNN().to(device)\n",
    "deep_net.eval()\n",
    "# select 058.pt\n",
    "model_path = f\"./models/{deep_net._name}/select/{deep_net._name}_059.pt\"\n",
    "deep_net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\"),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "_, test_acc = test_model(deep_net, test_dataloader, nn.CrossEntropyLoss())\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### calculate mean and std and define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_mean, t_std = get_mean_std(\"train\")\n",
    "print(\"mean values:\", t_mean)\n",
    "print(\"std values:\", t_std)\n",
    "\n",
    "val_transform = nn.Sequential(\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    ")\n",
    "test_transform = nn.Sequential(\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    ")\n",
    "train_transform = nn.Sequential(\n",
    "    T.RandomRotation(degrees=45),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.05),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.RandomErasing(p=0.5),\n",
    "    T.ColorJitter(brightness=0.3, hue=0.3),\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    ")\n",
    "#     T.ColorJitter(brightness=0.3, hue=0.3),\n",
    "#     T.RandomAffine(degrees=(-45, 45), translate=(0, 0.2), scale=(0.5, 1.0)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = STLData(\"train\")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "n_batches = 16\n",
    "img = []\n",
    "for idx, (data, _) in enumerate(dataloader):\n",
    "    if dataloader.dataset.transform is None:\n",
    "        data = order_tensor(data)\n",
    "    img += train_transform(data)\n",
    "    if idx == n_batches - 1:\n",
    "        break\n",
    "\n",
    "img = torch.stack(img)\n",
    "out = torchvision.utils.make_grid(img, nrow=n_batches // 2, padding=0)\n",
    "fig, ax = plt.subplots(figsize=(15, 45))\n",
    "ax.imshow(out.permute(1, 2, 0), interpolation=\"nearest\", aspect=\"auto\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "print(img.shape)\n",
    "print(\"Channel means: \", img.mean(dim=[0, 2, 3]))\n",
    "print(\"Max/Min values: \", img.max(), img.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_net = DeepCNN().to(device)\n",
    "model_cfg = {\n",
    "    \"model\": deep_net,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"momentum\": 0.9,  # only for SGD\n",
    "    \"weight_decay\": 0,\n",
    "    \"lr\": 5e-4,\n",
    "    \"lr_scheduler\": True,\n",
    "    \"batch_size\": 128,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"num_epochs\": 300,\n",
    "    \"train_transform\": train_transform,\n",
    "    \"val_transform\": val_transform,\n",
    "    \"test_transform\": test_transform,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_deep_T = train_model(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_log(log_deep_T, model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = DeepCNN().to(device)\n",
    "net.eval()\n",
    "# select 260.pt\n",
    "model_path = f\"./models/{net._name}/select/{net._name}_260.pt\"\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\"),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "_, test_acc = test_model(net, test_dataloader, nn.CrossEntropyLoss(), test_transform)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion Sensitivity for ShallowCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### LOAD MODEL\n",
    "device = \"cuda\"\n",
    "net = ShallowCNN().to(device)\n",
    "net.eval()\n",
    "# select 032.pt\n",
    "model_path = f\"./models/{net._name}/select/{net._name}_032.pt\"\n",
    "net.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    STLData(\"val\"),\n",
    "    batch_size=512,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    ")\n",
    "# K number of top images\n",
    "K = 5\n",
    "images = get_topk_by_class(net, dataloader, K, correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_rows = images.shape[0] // K\n",
    "n_cols = K * 2\n",
    "\n",
    "resize_trsfm = nn.Sequential(T.Resize(96))\n",
    "display = []\n",
    "for i in range(n_rows):\n",
    "    curr_label = i\n",
    "    img_batch = images[i * K : (i + 1) * K]\n",
    "    for j in range(K):\n",
    "        curr_img = img_batch[j].to(device)\n",
    "        display.append(curr_img)\n",
    "\n",
    "        heatmap = occlusion_single_img(\n",
    "            net, curr_img.unsqueeze(0), curr_label, kernel=(2, 2), stride=2\n",
    "        )\n",
    "        heatmap = heatmap.unsqueeze(0).to(device)\n",
    "        # cast single channel to 3 channel\n",
    "        heatmap = torch.cat([heatmap] * 3, 0)\n",
    "        heatmap = resize_trsfm(heatmap)\n",
    "        display.append(heatmap)\n",
    "# create (K * 2 * num_classes, 3, 96, 96) Tensor\n",
    "display = torch.stack(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = display.unsqueeze(0).reshape(10, 10, *display.shape[1::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 1200\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(40, 40), facecolor=\"white\")\n",
    "tmp = display.unsqueeze(0).reshape(10, 10, *display.shape[1::]).cpu()\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        out = tmp[i, j].permute(1, 2, 0)\n",
    "        if (j + 1) % 2 == 0:\n",
    "            prev_img = tmp[i, j - 1].unsqueeze(0).cuda()\n",
    "            heatmap = occlusion_single_img(\n",
    "                net, prev_img, i, kernel=(2, 2), stride=2\n",
    "            ).cpu()\n",
    "            ax[i, j].imshow(heatmap, interpolation=\"nearest\", aspect=\"equal\")\n",
    "            # ax[i, j].imshow(out)\n",
    "        else:\n",
    "            ax[i, j].imshow(out, interpolation=\"nearest\", aspect=\"equal\")\n",
    "        ax[i,j].axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.0001, hspace=0.0001)\n",
    "plt.savefig(f\"heatmap.png\", facecolor=fig.get_facecolor(), dpi=1200)\n",
    "plt.show()\n",
    "# ax.imshow(out.permute(1, 2, 0), )\n",
    "\n",
    "# ax[i, 0].imshow(out.permute(1, 2, 0), interpolation=\"nearest\", aspect=\"equal\")\n",
    "# ax[i, 0].set_xlabel(f\"{curr_label}, {class_labels[curr_label]}\")\n",
    "# ax[i, 0].set_title(\"Original Image\")\n",
    "\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# #     divider = make_axes_locatable(ax[i, 0])\n",
    "# #     cax0 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# #     cax0.set_yticks([])\n",
    "# #     cax0.set_xticks([])\n",
    "\n",
    "# heatmap, pred_label = occlusion_single_img(\n",
    "#     net, curr_img, curr_label, kernel=(2, 2), stride=2\n",
    "# )\n",
    "# heatmap = heatmap.detach().cpu().numpy().astype(np.float32)\n",
    "# hm_.append(heatmap)\n",
    "# # ax[i, 1].pcolormesh(heatmap)\n",
    "# ax[i, 1].imshow(heatmap, interpolation=\"nearest\", aspect=\"equal\")\n",
    "# #     ax[i, 1].imshow(\n",
    "# #         plt_heatmap, interpolation=\"nearest\", aspect=\"equal\"\n",
    "# #     )\n",
    "# ax[i, 1].set_xlabel(f\"{pred_label}, {class_labels[pred_label]}\")\n",
    "# ax[i, 1].set_title(\"Probability Heatmap\")\n",
    "\n",
    "# #     divider = make_axes_locatable(ax[i, 1])\n",
    "# #     cax1 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# #     # add colorbar\n",
    "# #     ColorbarBase(cax1, cmap=cm.jet, orientation=\"vertical\", vmin)\n",
    "\n",
    "# # fig.suptitle(\"Occlusion Sensitivity Study\")\n",
    "\n",
    "# n_heatmaps = 0\n",
    "# for path in Path.cwd().iterdir():\n",
    "#     if \"heatmap\" in str(path):\n",
    "#         n_heatmaps += 1\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
