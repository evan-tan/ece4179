{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_model = torch.nn.Linear(2, 1)\n",
    "lr = 0.1\n",
    "batch_steps = 128\n",
    "optimizer = torch.optim.Adam(tmp_model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=lr, steps_per_epoch=batch_steps, epochs=1000\n",
    ")\n",
    "lrs = []\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    for j in range(batch_steps):\n",
    "        scheduler.step()\n",
    "plt.title(\"OneCycleLR Illustration\")\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Learning Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader Example\n",
    "\n",
    "the following class reads the data for the third assignment and creates a torch dataset object for it. With this, you can easily use a dataloader to train your model. \n",
    "\n",
    "Due to size limit on moodle, the data for this assignment should be obtained from \n",
    "\n",
    "https://drive.google.com/file/d/1khzPamThzWScipEfMmOPevtfWV7Tx6UL/view?usp=sharing\n",
    "\n",
    "\n",
    "Make sure that the file \"hw3.npz\" is located properly (in this example, it should be in the same folder as this notebook).\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STLData(Dataset):\n",
    "    def __init__(self, mode=\"\", transform=None):\n",
    "        data = np.load(\"hw3.npz\")\n",
    "        if \"train\" in mode:\n",
    "            # trainloader\n",
    "            self.images = data[\"arr_0\"]\n",
    "            self.labels = data[\"arr_1\"]\n",
    "        elif \"val\" in mode:\n",
    "            # valloader\n",
    "            self.images = data[\"arr_2\"]\n",
    "            self.labels = data[\"arr_3\"]\n",
    "        elif \"test\" in mode:\n",
    "            # testloader\n",
    "            self.images = data[\"arr_4\"]\n",
    "            self.labels = data[\"arr_5\"]\n",
    "        else:\n",
    "            raise ValueError(\"mode should be 'train', 'val' or 'test'\")\n",
    "\n",
    "        # self.images = np.float32(self.images) / 1.0\n",
    "        # BUG FIXED: arr_N are all np.uint8,\n",
    "        # T.ToTensor() WILL NOT convert np.float32\n",
    "        self.images = np.uint8(self.images)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = self.images[idx, :]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how you can create a dataloader. \n",
    "First read the data. Note that the STL10 class can work with torchvision.transforms that are required in HW3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modified STLData class\n",
    "train_set = STLData(\"train\", T.ToTensor())\n",
    "val_set = STLData(\"val\", T.ToTensor())\n",
    "test_set = STLData(\"test\", T.ToTensor())\n",
    "\n",
    "batch_size = 100\n",
    "n_workers = 0 * multiprocessing.cpu_count()\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, num_workers=n_workers\n",
    ")\n",
    "image_batch, labels = next(iter(trainloader))\n",
    "\n",
    "# order tensor properly since if no T.Tensor() called in STLData\n",
    "if trainloader.dataset.transform is None:\n",
    "    image_batch = image_batch.permute(0, 3, 1, 2)\n",
    "\n",
    "fig, ax_arr = plt.subplots(2, 4)\n",
    "for i in range(8):\n",
    "    img = (image_batch[i]).permute(1, 2, 0)\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax_arr[row, col].imshow(img)\n",
    "    # ax_arr[i // 4, i % 4].axis(\"off\")\n",
    "    ax_arr[row, col].axes.get_yaxis().set_visible(False)\n",
    "    ax_arr[row, col].set_xlabel(labels[i].item())\n",
    "    ax_arr[row, col].set_xticklabels([])\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(10)\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a batchsize of 100, you can have a dataloader as follows for your training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class labels for STL dataset\n",
    "class_labels = [\n",
    "    \"airplane\",\n",
    "    \"bird\",\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"monkey\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def un_normalize(img, mean, std):\n",
    "    \"\"\"Un-normalize a NORMALIZED IMAGE given mean and std, as lists of 3 elements\"\"\"\n",
    "    mean, std = torch.Tensor(mean), torch.Tensor(std)\n",
    "\n",
    "    # change from (3,) to (1,3,1,1) for broadcasting\n",
    "    mean, std = mean.unsqueeze(1).T, std.unsqueeze(1).T\n",
    "    mean = mean.unsqueeze(2).unsqueeze(3)\n",
    "    std = std.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "    return img.mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def order_tensor(t_: torch.Tensor):\n",
    "    \"\"\"Ensure proper order of tensor dims since T.ToTensor() is inconsistent\"\"\"\n",
    "\n",
    "    # i.e. (B,H,W,C) -> (B,C,H,W)\n",
    "    if t_.ndim == 4:\n",
    "        h, w, c = t_.shape[1:4]\n",
    "        # ensure channels dim is at idx 1\n",
    "        if c < h or c < w:\n",
    "            return t_.permute(0, 3, 1, 2).contiguous()\n",
    "        else:\n",
    "            return t_\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_log(log, model_config, save=False, select=True):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    fig.set_figheight(7.5)\n",
    "    fig.set_figwidth(12)\n",
    "    # use ax1 for loss, ax2 for accuracy\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    epochs = model_config.get(\"num_epochs\")\n",
    "    x_axis = np.linspace(1, epochs, epochs)\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, len(log))))\n",
    "\n",
    "    # storage for all max/min values based on keys\n",
    "    selected = dict.fromkeys(log)\n",
    "\n",
    "    for key, values in log.items():\n",
    "        c = next(color)\n",
    "        key_str = key.replace(\"_\", \" \").title()\n",
    "        # plot data\n",
    "        if \"loss\" in key:\n",
    "            ax1.plot(x_axis, values, color=c, label=key_str)\n",
    "        elif \"acc\" in key:\n",
    "            ax2.plot(x_axis, values, color=c, label=key_str)\n",
    "        if select:\n",
    "            if \"loss\" in key:\n",
    "                # search for min\n",
    "                x = np.argmin(values) + 1\n",
    "                y = np.amin(values)\n",
    "                ax1.plot(\n",
    "                    x,\n",
    "                    y,\n",
    "                    color=c,\n",
    "                    label=f\"Min. {key_str}\",\n",
    "                    markersize=16,\n",
    "                    marker=\"d\",\n",
    "                    alpha=0.5,\n",
    "                )\n",
    "            elif \"acc\" in key:\n",
    "                # search for max\n",
    "                x = np.argmax(log[key]) + 1\n",
    "                y = np.amax(log[key])\n",
    "                ax2.plot(\n",
    "                    x,\n",
    "                    y,\n",
    "                    color=c,\n",
    "                    label=f\"Max. {key_str}\",\n",
    "                    markersize=16,\n",
    "                    marker=\"d\",\n",
    "                    alpha=0.5,\n",
    "                )\n",
    "            # save values in dict\n",
    "            # format: (epoch id, data value)\n",
    "            selected[key] = (x, y)\n",
    "\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.set_xlabel(\"Number of Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy (%)\")\n",
    "\n",
    "    # 0 = 'best', 7 = 'center right'\n",
    "    fig.legend(loc=7, bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f\"./LR_{model_config['lr']}_{model_config['num_epochs']}.jpg\")\n",
    "\n",
    "    plt.title(\n",
    "        f\"{model_cfg['model']._name} Learning Rate={str(model_cfg['lr'])} Batch Size={(model_cfg['batch_size'])} Max Val Acc={selected['val_acc'][1]} @ Epoch {selected['val_acc'][0]}\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    if select:\n",
    "        return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_model(net, data_generator, loss_fn, transform=None):\n",
    "    \"\"\"Function to easily test model on specified dataset\"\"\"\n",
    "    batch_loss, batch_steps = 0.0, 0\n",
    "    correct_pred, total_pred = 0, 0\n",
    "\n",
    "    net = net.to(device)\n",
    "    net.eval()\n",
    "    for batch_id, (data, label) in enumerate(data_generator):\n",
    "        data, label = data.to(device), label.long().to(device)\n",
    "\n",
    "        if data_generator.dataset.transform is None:\n",
    "            data = order_tensor(data)\n",
    "        if transform is not None:\n",
    "            data = transform(data.cuda())\n",
    "\n",
    "        output = net(data)\n",
    "        batch_loss += loss_fn(output, label).item()\n",
    "        batch_steps += 1\n",
    "\n",
    "        # indices where probability is maximum\n",
    "        _, pred_label = torch.max(output, 1)\n",
    "        correct_pred += (pred_label == label).sum().item()\n",
    "        total_pred += label.shape[0]\n",
    "\n",
    "    # average loss/acc across ALL batches\n",
    "    # i.e. ACROSS specified dataset\n",
    "    avg_loss = batch_loss / batch_steps\n",
    "    avg_acc = correct_pred / total_pred\n",
    "\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    logger = {\n",
    "        \"train_loss\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"val_loss\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"train_acc\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"val_acc\": np.zeros(config[\"num_epochs\"]),\n",
    "        \"test_acc\": np.zeros(config[\"num_epochs\"]),\n",
    "    }\n",
    "\n",
    "    #### LOAD DATA ####\n",
    "    b_size = config[\"batch_size\"]\n",
    "\n",
    "    # set to None if not specified\n",
    "    train_transform = config.get(\"train_transform\")\n",
    "    val_transform = config.get(\"val_transform\")\n",
    "    test_transform = config.get(\"test_transform\")\n",
    "\n",
    "    train_data = STLData(\"train\", T.ToTensor())\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=b_size,\n",
    "        num_workers=n_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    val_data = STLData(\"val\", T.ToTensor())\n",
    "    val_dataloader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=b_size,\n",
    "        num_workers=n_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    test_data = STLData(\"test\", T.ToTensor())\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=b_size,\n",
    "        num_workers=n_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    #### INSTANTIATE MODEL ####\n",
    "    net = config[\"model\"].to(device)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    if \"Adam\" in config[\"optimizer\"]:\n",
    "        optimizer = optim.Adam(\n",
    "            net.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "    elif \"SGD\" in config[\"optimizer\"]:\n",
    "        optimizer = optim.SGD(\n",
    "            net.parameters(),\n",
    "            lr=config[\"lr\"],\n",
    "            momentum=config[\"momentum\"],\n",
    "            weight_decay=config[\"weight_decay\"],\n",
    "        )\n",
    "\n",
    "    # TODO: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html\n",
    "    # https://spell.ml/blog/lr-schedulers-and-adaptive-optimizers-YHmwMhAAACYADm6F\n",
    "    if config.get(\"lr_scheduler\") is not None:\n",
    "        div_factor = config[\"lr_scheduler\"].get(\"div_factor\")\n",
    "        div_factor = 1e4 if div_factor is None else div_factor\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=config[\"lr\"],\n",
    "            steps_per_epoch=len(train_dataloader),\n",
    "            epochs=config[\"num_epochs\"],\n",
    "            final_div_factor=div_factor,\n",
    "        )\n",
    "\n",
    "    #### BEGIN TRAINING ####\n",
    "    start_time = time.time()\n",
    "    best_val_acc = 0\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(f\"Train Transforms: {train_transform}\")\n",
    "    pp.pprint(f\"Test Transforms: {test_transform}\")\n",
    "    pp.pprint(f\"Val Transforms: {val_transform}\")\n",
    "\n",
    "    for j in range(config[\"num_epochs\"]):\n",
    "        ## START OF EPOCH ##\n",
    "        train_loss, train_steps = 0.0, 0\n",
    "        net.train()\n",
    "\n",
    "        for batch_id, (data, label) in enumerate(train_dataloader):\n",
    "            data, label = data.to(device), label.long().to(device)\n",
    "\n",
    "            if train_dataloader.dataset.transform is None:\n",
    "                data = order_tensor(data)\n",
    "            if train_transform is not None:\n",
    "                data = train_transform(data.cuda())\n",
    "\n",
    "            # forwardfacecolor=fig.get_facecolor()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = net(data)\n",
    "                loss = loss_function(output, label)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "\n",
    "            if config.get(\"lr_scheduler\") is not None:\n",
    "                # OneCycleLR steps inside dataloader loop\n",
    "                scheduler.step()\n",
    "\n",
    "        ## END OF EPOCH ##\n",
    "\n",
    "        # average training loss for 1 epoch\n",
    "        train_loss /= train_steps\n",
    "\n",
    "        # test model on validation dataset\n",
    "        _, train_acc = test_model(net, train_dataloader, loss_function, train_transform)\n",
    "        val_loss, val_acc = test_model(\n",
    "            net, val_dataloader, loss_function, val_transform\n",
    "        )\n",
    "        _, test_acc = test_model(net, test_dataloader, loss_function, test_transform)\n",
    "\n",
    "        logger[\"train_loss\"][j] = train_loss\n",
    "        logger[\"val_loss\"][j] = val_loss\n",
    "        logger[\"train_acc\"][j] = train_acc\n",
    "        logger[\"val_acc\"][j] = val_acc\n",
    "        logger[\"test_acc\"][j] = test_acc\n",
    "\n",
    "        if config[\"log_training\"] and (j + 1) % config[\"log_interval\"] == 0:\n",
    "            print(\n",
    "                f\"Epoch:{j+1}/{config['num_epochs']}\",\n",
    "                f\"Train Loss: {logger['train_loss'][j]:.4f}\",\n",
    "                f\"Train Acc: {logger['train_acc'][j]:.4f}\",\n",
    "                f\"Val Loss: {logger['val_loss'][j]:.4f}\",\n",
    "                f\"Val Acc: {logger['val_acc'][j]:.4f}\",\n",
    "                f\"Test Acc: {logger['test_acc'][j]:.4f}\",\n",
    "            )\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            if config[\"save_model\"]:\n",
    "                # make sure folder is created to place saved checkpoints\n",
    "                path = Path.cwd() / \"models\" / net._name\n",
    "                if not path.exists():\n",
    "                    path.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "                # pad with appropriate number of zeros i.e. epoch 10 named as 010\n",
    "                checkpoint_num = str(j + 1).zfill(len(str(config[\"num_epochs\"])))\n",
    "                model_path = f\"./models/{net._name}/{net._name}_{checkpoint_num}.pt\"\n",
    "                torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    print(f\"{config['num_epochs']} epochs took {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    if config[\"log_training\"]:\n",
    "        return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def store_model_outputs(net, data_generator, transform=None):\n",
    "    images = []  # (N,)\n",
    "    labels = []  # (N,)\n",
    "    outputs = []  # (N,10)\n",
    "\n",
    "    net.eval()\n",
    "    # loop through specified dataset, collect all scores per class\n",
    "    for batch_id, (data, label) in enumerate(data_generator):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "\n",
    "        if data_generator.dataset.transform is None:\n",
    "            data = order_tensor(data)\n",
    "        # don't transform since we're just storing model outputs for Q1.2,Q1.3\n",
    "        if transform is not None:\n",
    "            data = transform(data)\n",
    "\n",
    "        output = net(data)\n",
    "        images += data\n",
    "        labels += label\n",
    "        outputs += output\n",
    "\n",
    "    # convert lists of tensors to single tensor and overwrite variables\n",
    "    images = torch.stack(images).cpu()\n",
    "    labels = torch.stack(labels).cpu()  # torch.Tensor(labels) also works\n",
    "    outputs = torch.stack(outputs).cpu()\n",
    "\n",
    "    return labels, outputs, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topk_by_class(net, dataloader, n_img, correct=True):\n",
    "    \"\"\"Return Top K images by confidence of prediction by class\"\"\"\n",
    "\n",
    "    labels, outputs, images = store_model_outputs(net, dataloader)\n",
    "    # apply softmax\n",
    "    confidence = F.softmax(outputs, dim=1)\n",
    "    # find correct labels indices\n",
    "    idx = confidence.argmax(dim=1) == labels\n",
    "\n",
    "    if correct != True:\n",
    "        idx = ~idx  # jank bitwise complement\n",
    "\n",
    "    images = images[idx]\n",
    "    labels = labels[idx]\n",
    "    confidence = confidence[idx]\n",
    "\n",
    "    display_img = []\n",
    "    for j in range(confidence.shape[1]):\n",
    "        top_n_idx = torch.argsort(confidence[:, j], descending=True)[:n_img]\n",
    "        display_img += images[top_n_idx]\n",
    "\n",
    "    display_img = torch.stack(display_img).cpu()\n",
    "\n",
    "    return display_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_model_outputs(net, dataloader, correct=True):\n",
    "    \"\"\"Visualize model's top 5 images for each class on val dataset, defaults to correct predictions\"\"\"\n",
    "    num_img = 5\n",
    "    display_img = get_topk_by_class(net, dataloader, num_img, correct)\n",
    "\n",
    "    out = torchvision.utils.make_grid(display_img, nrow=num_img, padding=0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 20))\n",
    "    ax.imshow(out.permute(1, 2, 0), interpolation=\"nearest\", aspect=\"auto\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "\n",
    "    # adding class labels to y-axis\n",
    "    # appropriately space labels\n",
    "    offset = int(display_img.shape[2] / 2)\n",
    "    max_dim = int(display_img.shape[0] / num_img * display_img.shape[2])\n",
    "    spacing = int(display_img.shape[2])\n",
    "    yticks = [i for i in range(0 + offset, max_dim, spacing)]\n",
    "\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(class_labels)\n",
    "    mode_str = \"Correct\" if correct else \"Wrong\"\n",
    "    ax.set_title(\n",
    "        f\"Visualizing Top {num_img} {mode_str} image predictions for each class\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_confusion_matrix(\n",
    "    net,\n",
    "    data_generator,\n",
    "    labels,\n",
    "):\n",
    "    \"\"\"Create confusion matrix based for a given dataset and respective labels\"\"\"\n",
    "\n",
    "    true_labels, outputs, _ = store_model_outputs(net, data_generator)\n",
    "\n",
    "    true_labels = true_labels.cpu()\n",
    "    pred_labels = outputs.argmax(1).cpu()\n",
    "    n_classes = outputs.shape[1]\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = np.zeros((n_classes, n_classes))\n",
    "    for i, val in enumerate(outputs):\n",
    "        cm[true_labels[i], pred_labels[i]] += 1\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.figure(figsize=(11, 8))\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\".0f\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.ylabel(\"True label\", rotation=0)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "    if type(data_generator) == DataLoader:\n",
    "        if len(data_generator.dataset) == len(STLData(\"test\")):\n",
    "            dataset_str = \"Test\"\n",
    "        elif len(data_generator.dataset) == len(STLData(\"train\")):\n",
    "            dataset_str = \"Train\"\n",
    "        elif len(data_generator.dataset) == len(STLData(\"val\")):\n",
    "            dataset_str = \"Validation\"\n",
    "\n",
    "    plt.title(f\"Confusion Matrix for {dataset_str} Dataset\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean_std(mode=\"\"):\n",
    "    \"\"\"Calculate mean and std across image channels from specified dataset\"\"\"\n",
    "    assert mode == \"train\" or mode == \"val\" or mode == \"test\"\n",
    "    dataset = STLData(mode, T.ToTensor())\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=len(dataset),  # random batch size\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    mean, std = 0, 0\n",
    "    n_samples = 0\n",
    "    for _, (data, _) in enumerate(dataloader):\n",
    "        if dataloader.dataset.transform is None:\n",
    "            data = order_tensor(data)\n",
    "\n",
    "        # DO NOT TRANSFORM i.e. ColorJitter etc.!!!!!\n",
    "        data = data.flatten(2).to(\"cpu\")\n",
    "        # take across each channel\n",
    "        # dims=(B,C,H*W)\n",
    "        # calculate mean/std of each image\n",
    "        # then sum across batch\n",
    "        mean += data.mean(dim=2).sum(dim=0)\n",
    "        std += data.std(dim=2).sum(dim=0)\n",
    "        n_samples += data.shape[0]\n",
    "    mean /= n_samples\n",
    "    std /= n_samples\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def occlusion_single_img(net, img, true_label, kernel: tuple, stride: int):\n",
    "    \"\"\"Perform Occlusion Sensitivity on a single img\"\"\"\n",
    "    if img.ndim == 4:\n",
    "        H, W = img.shape[2:4]\n",
    "    elif img.ndim == 3:\n",
    "        H, W = img.shape[1:3]\n",
    "\n",
    "    # determine output dimensions\n",
    "    H_out = int(np.floor((W - kernel[0]) / stride) + 1)\n",
    "    W_out = int(np.floor((H - kernel[1]) / stride) + 1)\n",
    "    heatmap = torch.zeros((H_out, W_out))\n",
    "\n",
    "    for i in range(H_out):\n",
    "        for j in range(W_out):\n",
    "            img_mod = T.functional.erase(\n",
    "                img, i * stride, j * stride, kernel[0], kernel[1], v=0\n",
    "            )\n",
    "\n",
    "            # run inference\n",
    "            net.eval()\n",
    "            output = net(img_mod)\n",
    "            # apply softmax\n",
    "            probs = F.softmax(output, dim=1)\n",
    "\n",
    "            # setting the heatmap location to probability value\n",
    "            if torch.is_tensor(true_label):\n",
    "                heatmap[i, j] = probs.squeeze()[true_label.item()].item()\n",
    "            else:\n",
    "                # when true_label is a str\n",
    "                heatmap[i, j] = probs.squeeze()[true_label].item()\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ShallowCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShallowCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShallowCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, (7, 7), stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(96, 64, (5, 5), stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(64, 128, (3, 3), stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(1152, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._name = self.__class__.__name__\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # flatten all dimensions except batch\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shallow_net = ShallowCNN().to(device)\n",
    "# gamma is how much to reduce LR every time scheduler is triggered\n",
    "# LR between 2.21e-4 and 8.05e-4\n",
    "model_cfg = {\n",
    "    \"model\": shallow_net,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"momentum\": 0.9,  # only for SGD\n",
    "    \"weight_decay\": 0,\n",
    "    \"lr\": 2.21e-4,\n",
    "    \"lr_scheduler\": {\"div_factor\": 1e2},\n",
    "    \"batch_size\": 128,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"num_epochs\": 60,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log_shallow = train_model(model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_log(log_shallow, model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shallow_net = ShallowCNN().to(device)\n",
    "shallow_net.eval()\n",
    "\n",
    "# select 33.pt\n",
    "model_path = f\"models/{shallow_net._name}/select/{shallow_net._name}_33.pt\"\n",
    "shallow_net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\", T.ToTensor()),\n",
    "    batch_size=256,\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "_, test_acc = test_model(shallow_net, test_dataloader, nn.CrossEntropyLoss())\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(\n",
    "    STLData(\"val\", T.ToTensor()),\n",
    "    batch_size=128,\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correct images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_model_outputs(shallow_net, val_dataloader, correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrong images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_model_outputs(shallow_net, val_dataloader, correct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    STLData(\"train\", T.ToTensor()),\n",
    "    batch_size=128,\n",
    "    num_workers=n_workers,\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    ")\n",
    "make_confusion_matrix(shallow_net, train_dataloader, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(\n",
    "    STLData(\"val\", T.ToTensor()),\n",
    "    batch_size=128,\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "make_confusion_matrix(shallow_net, val_dataloader, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\", T.ToTensor()),\n",
    "    batch_size=128,\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "make_confusion_matrix(shallow_net, test_dataloader, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DeepCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "\n",
    "        self.blocks = self._build_blocks()\n",
    "        # global average pooling\n",
    "        # since the output of our conv blocks is (6,6)\n",
    "        self.gap = nn.AvgPool2d(kernel_size=6, stride=1)\n",
    "        self.fc1 = nn.Linear(192, 10)\n",
    "\n",
    "        self._name = self.__class__.__name__\n",
    "\n",
    "    def _build_blocks(self):\n",
    "        conv_blk_dims = [3, 32, 64, 128, 192]\n",
    "        blocks_list = []\n",
    "        for i in range(len(conv_blk_dims) - 1):\n",
    "            conv_block = self._create_conv_block(conv_blk_dims[i], conv_blk_dims[i + 1])\n",
    "            named_block = (f\"Conv-Blk-{i+1}\", conv_block)\n",
    "            # blocks_list.append(conv_block)\n",
    "            blocks_list.append(named_block)\n",
    "\n",
    "        # return nn.Sequential(*blocks_list)\n",
    "        return nn.Sequential(OrderedDict(blocks_list))\n",
    "\n",
    "    def _create_conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Create conv_block based on in/out channels\"\"\"\n",
    "        conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, (3, 3), stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, (1, 1), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, (3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        return conv_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        x = self.gap(x)\n",
    "        # flatten all dimensions except batch\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## No transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_net = DeepCNN().to(device)\n",
    "# gamma is how much to reduce LR every time scheduler is triggered\n",
    "model_cfg = {\n",
    "    \"model\": deep_net,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"momentum\": 0.9,  # only for SGD\n",
    "    \"weight_decay\": 0,\n",
    "    \"lr\": 2.5e-4,\n",
    "    \"lr_scheduler\": {\"div_factor\": 2},\n",
    "    \"batch_size\": 128,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"num_epochs\": 150,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log_deep = train_model(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log(log_deep, model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_net = DeepCNN().to(device)\n",
    "deep_net.eval()\n",
    "# select 128.pt\n",
    "model_path = f\"./models/{deep_net._name}/select/{deep_net._name}_128.pt\"\n",
    "deep_net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\", T.ToTensor()),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "_, test_acc = test_model(deep_net, test_dataloader, nn.CrossEntropyLoss())\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### calculate mean and std and define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_mean, t_std = get_mean_std(\"train\")\n",
    "print(\"mean values:\", t_mean)\n",
    "print(\"std values:\", t_std)\n",
    "\n",
    "t_mean = (t_mean).tolist()\n",
    "t_std = (t_std).tolist()\n",
    "print(\"modified mean values:\", t_mean)\n",
    "print(\"modified std values:\", t_std)\n",
    "\n",
    "val_transform = nn.Sequential(\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    ")\n",
    "test_transform = nn.Sequential(\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    ")\n",
    "\n",
    "train_transform = nn.Sequential(\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    "    T.RandomRotation(degrees=45),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.05),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.RandomErasing(p=0.5),\n",
    ")\n",
    "#     T.ColorJitter(brightness=(0, 0.5), hue=(-0.3, 0.3)),\n",
    "#     T.RandomAffine(degrees=(-45, 45), translate=(0, 0.2), scale=(0.5, 1.0)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = STLData(\"train\", T.ToTensor())\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "img = []\n",
    "for idx, (data, _) in enumerate(dataloader):\n",
    "    if dataloader.dataset.transform is None:\n",
    "        data = order_tensor(data)\n",
    "    tmp = train_transform(data)\n",
    "    img += tmp\n",
    "img = torch.stack(img)\n",
    "print(img.shape)\n",
    "print(\"Channel std after normalization: \", img.std(dim=[0, 2, 3]))\n",
    "print(\"Channel means after normalization: \", img.mean(dim=[0, 2, 3]))\n",
    "print(\"Max/Min values after normalization: \", img.max(), img.min())\n",
    "n_img = 256\n",
    "display = img[:n_img]\n",
    "out = torchvision.utils.make_grid(display, nrow=16 // 2, padding=0)\n",
    "fig, ax = plt.subplots(figsize=(15, 45))\n",
    "ax.imshow(out.permute(1, 2, 0), interpolation=\"nearest\", aspect=\"auto\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_net = DeepCNN().to(device)\n",
    "model_cfg = {\n",
    "    \"model\": deep_net,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"momentum\": 0.9,  # only for SGD\n",
    "    \"weight_decay\": 0,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_scheduler\": {\"div_factor\": 1e3},\n",
    "    \"batch_size\": 64,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"num_epochs\": 300,\n",
    "    \"train_transform\": train_transform,\n",
    "    \"val_transform\": val_transform,\n",
    "    \"test_transform\": test_transform,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tmp = train_model(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_log(tmp, model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# old plot\n",
    "plot_log(tmp, model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = DeepCNN().to(device)\n",
    "net.eval()\n",
    "# select 282.pt or 269.pt\n",
    "model_path = f\"./models/{net._name}/select/{net._name}_282.pt\"\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\", T.ToTensor()),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "_, test_acc = test_model(net, test_dataloader, nn.CrossEntropyLoss(), test_transform)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        self.blocks = self._build_blocks()\n",
    "        self.fc1 = nn.Linear(384, 192)\n",
    "        self.fc2 = nn.Linear(192, 10)\n",
    "        self.ap = nn.AvgPool2d(kernel_size=6, stride=1, padding=0)\n",
    "        self.mp = nn.MaxPool2d(kernel_size=6, stride=1, padding=0)\n",
    "        # # (6,6) -> (3,3)\n",
    "        # self.ap = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # # (3,3) -> (1,1)\n",
    "        # self.mp = nn.MaxPool2d(kernel_size=3, stride=1, padding=0)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        self._name = self.__class__.__name__\n",
    "\n",
    "    def _build_blocks(self):\n",
    "        conv_blk_dims = [3, 32, 64, 128, 192]\n",
    "        blocks_list = []\n",
    "        for i in range(len(conv_blk_dims) - 1):\n",
    "            conv_block = self._create_conv_block(conv_blk_dims[i], conv_blk_dims[i + 1])\n",
    "            blocks_list.append((f\"Conv-Blk-{i+1}\", conv_block))\n",
    "\n",
    "        return nn.Sequential(OrderedDict(blocks_list))\n",
    "\n",
    "    def _create_conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Create conv_block based on in/out channels\"\"\"\n",
    "        conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, (5, 5), stride=2, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(out_channels, out_channels, (3, 3), stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        return conv_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        # x = self.ap(x)\n",
    "        # x = self.mp(x)\n",
    "\n",
    "        # concatenate pool2d to preserve more information\n",
    "        x = torch.cat([self.mp(x), self.ap(x)], dim=1)\n",
    "        # flatten all dimensions except batch\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.lrelu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(CustomCNN())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_mean, t_std = get_mean_std(\"train\")\n",
    "t_mean = t_mean.tolist()\n",
    "t_std = t_std.tolist()\n",
    "print(\"mean values:\", t_mean)\n",
    "print(\"std values:\", t_std)\n",
    "\n",
    "val_transform = nn.Sequential(\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    ")\n",
    "test_transform = nn.Sequential(\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    ")\n",
    "\n",
    "train_transform = nn.Sequential(\n",
    "    T.Normalize(mean=t_mean, std=t_std),\n",
    "    T.RandomRotation(degrees=45),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.05),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.RandomErasing(p=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_net = CustomCNN().to(device)\n",
    "model_cfg = {\n",
    "    \"model\": custom_net,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"momentum\": 0.9,  # only for SGD\n",
    "    \"weight_decay\": 0,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_scheduler\": {\"div_factor\": 1e3},\n",
    "    \"batch_size\": 64,\n",
    "    \"log_training\": True,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"num_epochs\": 300,\n",
    "    \"train_transform\": train_transform,\n",
    "    \"val_transform\": val_transform,\n",
    "    \"test_transform\": test_transform,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log_custom = train_model(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_log(log_custom, model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = CustomCNN().to(device)\n",
    "net.eval()\n",
    "# select 294.pt\n",
    "model_path = f\"./models/{net._name}/select/{net._name}_294.pt\"\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    STLData(\"test\", T.ToTensor()),\n",
    "    batch_size=model_cfg[\"batch_size\"],\n",
    "    num_workers=n_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "_, test_acc = test_model(net, test_dataloader, nn.CrossEntropyLoss(), test_transform)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_cnn = DeepCNN().to(device)\n",
    "summary(deep_cnn, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_cnn = CustomCNN().to(device)\n",
    "summary(custom_cnn, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion Sensitivity for ShallowCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### LOAD MODEL\n",
    "device = \"cuda\"\n",
    "net = ShallowCNN().to(device)\n",
    "net.eval()\n",
    "# select 33.pt\n",
    "model_path = f\"./models/{net._name}/select/{net._name}_33.pt\"\n",
    "net.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    STLData(\"val\", T.ToTensor()),\n",
    "    batch_size=512,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    ")\n",
    "# K number of top images\n",
    "K = 5\n",
    "images = get_topk_by_class(net, dataloader, K, correct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cols = 4\n",
    "n_rows = int(images.shape[0] * 2 / n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display = []\n",
    "for i in range(images.shape[0]):\n",
    "    curr_img = images[i]\n",
    "    display.append(curr_img)\n",
    "    dummy = torch.zeros(3, 96, 96)\n",
    "    display.append(dummy)\n",
    "# create (K * 2 * num_classes, 3, 96, 96) Tensor\n",
    "display = torch.stack(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 600\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(5, 25), facecolor=\"white\")\n",
    "tmp = display.unsqueeze(0).reshape(n_rows, n_cols, *display.shape[1::])\n",
    "import math\n",
    "\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        out = tmp[i, j].permute(1, 2, 0)\n",
    "        if (j + 1) % 2 == 0:\n",
    "            prev_img = tmp[i, j - 1].unsqueeze(0).cuda()\n",
    "            label = math.floor(i / K)\n",
    "            heatmap = occlusion_single_img(\n",
    "                net, prev_img, label, kernel=(8, 8), stride=8\n",
    "            ).cpu()\n",
    "            shown_img = ax[i, j].imshow(\n",
    "                heatmap, interpolation=\"nearest\", aspect=\"equal\"\n",
    "            )\n",
    "            cbar = fig.colorbar(shown_img, ax=ax[i, j], format=\"%.4f\")\n",
    "            cbar.ax.tick_params(labelsize=5)\n",
    "        else:\n",
    "            ax[i, j].imshow(out, interpolation=\"nearest\", aspect=\"equal\")\n",
    "        ax[i, j].axis(\"off\")\n",
    "# lmao\n",
    "# n_heatmaps = 0\n",
    "# for path in Path.cwd().iterdir():\n",
    "#     if \"heatmap\" in str(path):\n",
    "#         n_heatmaps += 1\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "plt.savefig(f\"heatmap.svg\", format=\"svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
